{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Image_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:tensorflow113]",
      "language": "python",
      "name": "conda-env-tensorflow113-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEChaney/ML-RayCast-Experiments/blob/master/supervised_learning_4_localization_simpleCNN_can_train_single_or_stacked_frame.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jw1arH2vxVXK",
        "outputId": "4c8374a1-eb68-4f1f-b986-256735afc8e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "!git clone https://github.com/LEChaney/ML-RayCast-Experiments\n",
        "%cd ML-RayCast-Experiments\n",
        "%pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML-RayCast-Experiments'...\n",
            "remote: Enumerating objects: 135, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 341 (delta 67), reused 23 (delta 7), pack-reused 206\u001b[K\n",
            "Receiving objects: 100% (341/341), 46.01 MiB | 24.59 MiB/s, done.\n",
            "Resolving deltas: 100% (175/175), done.\n",
            "/content/ML-RayCast-Experiments\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ML-RayCast-Experiments'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nR2rN0ieyYQ5",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "def rotate(image_path):\n",
        "    \"\"\"\n",
        "    Rotate the given photo the amount of given degreesk, show it and save it\n",
        "    @param image_path: The path to the image to edit\n",
        "    @param degrees_to_rotate: The number of degrees to rotate the image\n",
        "    @param saved_location: Path to save the cropped image\n",
        "    \"\"\"\n",
        "    degrees_to_rotate = 180\n",
        "    image_obj = Image.open(image_path)\n",
        "    rotated_image = image_obj.rotate(degrees_to_rotate)\n",
        "    rotated_image.save(\"000.png\")\n",
        "    im = cv2.imread(\"000.png\")\n",
        "    #plt.imshow(im)\n",
        "    #plt.show()\n",
        "    return im\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BqsexcF4qXfE",
        "outputId": "e638a655-db4c-466e-b51b-b5ae43101938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "os.environ['SDL_VIDEODRIVER']='dummy'\n",
        "file_directory = os.getcwd()\n",
        "os.chdir(\"/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master\")\n",
        "print(os.getcwd())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iY7nyqTkNMef",
        "outputId": "179f04f7-b881-4b3a-d9cd-bcc544f15f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import sys\n",
        "#sys.path.pop(1)\n",
        "sys.path.insert(1,\"/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master/game\")\n",
        "print(sys.path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master/game', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F-j-vysiwaMd",
        "outputId": "6be30dab-9945-4d8b-e193-da5ea71082ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "%pip install pygame"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 4.0MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-1.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GGMYTHT4OLy4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "0a4aa2d2-37a3-48e0-aab3-8f62eea65851"
      },
      "source": [
        "sys.path.append(\"game/\")\n",
        "import wrapped_flappy_bird as game\n",
        "import numpy as np\n",
        "import flappy_bird_utils\n",
        "import cv2\n",
        "import sys\n",
        "import random\n",
        "import pygame\n",
        "import pygame.surfarray as surfarray\n",
        "from pygame.locals import *\n",
        "from itertools import cycle\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "#from cStringIO import StringIO\n",
        "import IPython.display\n",
        "\n",
        "import argparse\n",
        "import skimage as skimage\n",
        "from skimage import transform, color, exposure\n",
        "from skimage.transform import rotate\n",
        "from skimage.viewer import ImageViewer\n",
        "import json\n",
        "\n",
        "from collections import deque"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 1.9.6\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/viewer/__init__.py:6: UserWarning: Viewer requires Qt\n",
            "  warn('Viewer requires Qt')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "epVQmcWzpGRU",
        "outputId": "8c34438f-0f65-48c7-b6f6-b7da304ed911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "GAME = 'bird' # the name of the game being played for log files\n",
        "CONFIG = 'nothreshold'\n",
        "ACTIONS = 2 # number of valid actions\n",
        "GAMMA = 0.99 # decay rate of past observations\n",
        "OBSERVATION = 2 #3200. # timesteps to observe before training\n",
        "EXPLORE = 3000000. # frames over which to anneal epsilon\n",
        "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
        "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
        "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
        "BATCH = 32 # size of minibatch\n",
        "FRAME_PER_ACTION = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "FPS = 30\n",
        "SCREENWIDTH  = 288\n",
        "SCREENHEIGHT = 512\n",
        "\n",
        "pygame.init()\n",
        "pygame.display.init()\n",
        "pygame.display.set_mode((1, 1))\n",
        "FPSCLOCK = pygame.time.Clock()\n",
        "SCREEN = pygame.Surface((SCREENWIDTH, SCREENHEIGHT)).convert_alpha()\n",
        "pygame.display.set_caption('Flappy Bird')\n",
        "\n",
        "IMAGES, SOUNDS, HITMASKS = flappy_bird_utils.load()\n",
        "PIPEGAPSIZE = 100 # gap between upper and lower part of pipe\n",
        "BASEY = SCREENHEIGHT * 0.79\n",
        "\n",
        "PLAYER_WIDTH = IMAGES['player'][0].get_width()\n",
        "PLAYER_HEIGHT = IMAGES['player'][0].get_height()\n",
        "PIPE_WIDTH = IMAGES['pipe'][0].get_width()\n",
        "PIPE_HEIGHT = IMAGES['pipe'][0].get_height()\n",
        "BACKGROUND_WIDTH = IMAGES['background'].get_width()\n",
        "\n",
        "PLAYER_INDEX_GEN = cycle([0, 1, 2, 1])\n",
        "\n",
        "img_rows , img_cols = 80, 80\n",
        "#Convert image into Black and white\n",
        "img_channels = 4 #We stack 4 frames\n",
        "\n",
        "game_state = game.GameState()\n",
        "do_nothing = np.zeros(ACTIONS)\n",
        "do_nothing[0] = 1\n",
        "game_state.frame_step(do_nothing)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0, 0, 0]]], dtype=uint8), 0.1, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLkjBOh4Y4FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image_from_coords(data_list):\n",
        "  \n",
        "    CaseNo = int(float(data_list[0]))\n",
        "    game_state.playerx = int(float(data_list[1]))# + SCREENWIDTH /2)\n",
        "    game_state.playery = int(float(data_list[2]))# + SCREENWIDTH /2)\n",
        "    game_state.playerIndex = int(float(data_list[3]))        \n",
        "\n",
        "    game_state.upperPipes = []\n",
        "    game_state.lowerPipes = []\n",
        "\n",
        "    for i in range(4,len(data_list),4):\n",
        "\n",
        "        newPipe = game.getRandomPipe()\n",
        "        game_state.upperPipes.append(newPipe[0])\n",
        "        game_state.upperPipes[int((i-4)/4)]['x'] = int(float(data_list[i]))# + SCREENWIDTH /2)\n",
        "        game_state.upperPipes[int((i-4)/4)]['y'] = int(float(data_list[i+1]))# + SCREENWIDTH /2)\n",
        "\n",
        "        game_state.lowerPipes.append(newPipe[1])\n",
        "        game_state.lowerPipes[int((i-4)/4)]['x'] = int(float(data_list[i+2]))# + SCREENWIDTH /2)\n",
        "#         print(data_list)\n",
        "#         print(len(data_list))\n",
        "#         print(i+3)\n",
        "        game_state.lowerPipes[int((i-4)/4)]['y'] = int(float(data_list[i+3]))# + SCREENWIDTH /2)\n",
        "\n",
        "    # draw sprites\n",
        "    SCREEN.blit(IMAGES['background'], (0,0))\n",
        "\n",
        "    for uPipe, lPipe in zip(game_state.upperPipes, game_state.lowerPipes):\n",
        "        SCREEN.blit(IMAGES['pipe'][0], (uPipe['x'], uPipe['y']))\n",
        "        SCREEN.blit(IMAGES['pipe'][1], (lPipe['x'], lPipe['y']))\n",
        "\n",
        "    SCREEN.blit(IMAGES['base'], (game_state.basex, BASEY))\n",
        "    # print score so player overlaps the score\n",
        "    # showScore(self.score)\n",
        "    SCREEN.blit(IMAGES['player'][game_state.playerIndex],\n",
        "                (game_state.playerx, game_state.playery))\n",
        "\n",
        "    image_data = pygame.surfarray.array3d(SCREEN)\n",
        "    \n",
        "#     IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "#     plt.show()\n",
        "    \n",
        "    image_data = skimage.color.rgb2gray(image_data)\n",
        "    image_data = skimage.transform.resize(image_data,(80,80))\n",
        "    image_data = skimage.exposure.rescale_intensity(image_data, out_range=(0,255))\n",
        "\n",
        "    image_data = image_data / 255.0\n",
        "\n",
        "    image_data = image_data.reshape(1, image_data.shape[0], image_data.shape[1], 1) #1x80x80x1\n",
        "\n",
        "    label = np.array([game_state.playerx, game_state.playery])\n",
        "    \n",
        "#     #print(type(image_data))\n",
        "#     print(\"image_data\" ,image_data)\n",
        "#     print(\"image_data.shape: \", image_data.shape)\n",
        "#     IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "#     #plt.show()\n",
        "\n",
        "    return image_data, label\n",
        "\n",
        "def gen_batch_stacked_frames(file, state, state_labels, bs, D, mode):\n",
        "    \n",
        "    images=[]\n",
        "    labels=[]\n",
        "\n",
        "    while len(images) < bs:  \n",
        "        \n",
        "        current = file.readline().rstrip()\n",
        "\n",
        "        #if reach end of the file start again\n",
        "        if current == \"\":\n",
        "            \n",
        "            file.seek(0)\n",
        "\n",
        "            current = file.readline().rstrip()\n",
        "            \n",
        "            if mode == \"eval\":\n",
        "                break\n",
        "            \n",
        "            data_list = current.split(',')\n",
        "            data_list = [x for x in data_list if str(x) != 'nan']\n",
        "  \n",
        "            image_data, state_label = get_image_from_coords(data_list)\n",
        "            image_data = image_data.reshape(80, 80)\n",
        "            state = np.stack((image_data, image_data, image_data, image_data), axis=2)\n",
        "            state = state.reshape(1, state.shape[0], state.shape[1], state.shape[2])  #1*80*80*4\n",
        "#             state_label = np.array(state_label)\n",
        "            state_labels = np.stack((state_label, state_label, state_label, state_label), axis=0).flatten()\n",
        "#             print(state_labels)\n",
        "            state_labels = state_labels.flatten()\n",
        "#             print(state_labels) \n",
        "            #state = state.reshape(state.shape[0],)\n",
        "            \n",
        "            # store the transition in D\n",
        "            D.append((state, state_labels))   \n",
        "            \n",
        "#             if current[0] == \"-\":\n",
        "#                 continue\n",
        "        else:   \n",
        "            \n",
        "            data_list = current.split(',')\n",
        "#             if len(images) == 10:\n",
        "#                 print(data_list)\n",
        "            \n",
        "            data_list = [x for x in data_list if str(x) != 'nan']\n",
        "            \n",
        "#             print('no. in batch: ', len(images))\n",
        "            \n",
        "#             if len(images) == 10:\n",
        "#                 print(data_list)\n",
        "#                   print(len(data_list))\n",
        "            \n",
        "            image_data, state_label = get_image_from_coords(data_list)\n",
        "\n",
        "    #             state.append(image_data)\n",
        "    #             state_labels.append(label)\n",
        "#             print(state.shape)\n",
        "#             print(image_data.shape)\n",
        "            state = np.append(image_data, state[:, :, :, :3], axis=3)\n",
        "#             state_labels = np.append(state_label, state_labels[:6]).flatten()\n",
        "#             print(state_label.shape)\n",
        "#             print(state_labels.shape)\n",
        "            state_labels = np.concatenate((state_label, state_labels[:6]), axis=0)\n",
        "#             print(state_labels)\n",
        "            state_labels = state_labels.flatten()\n",
        "#             print(state_labels) \n",
        "            #state = np.array(state)\n",
        "            #state = state.reshape(state.shape[0],)\n",
        "        \n",
        "        # store the transition in D\n",
        "        D.append((state, state_labels))\n",
        "        if len(D) > REPLAY_MEMORY:\n",
        "            D.popleft()\n",
        "#         print(len(D))\n",
        "        \n",
        "        # training with experience replay\n",
        "        miniBatch = random.sample(D,1)\n",
        "        gen_state, gen_label = zip(*miniBatch)\n",
        "        images.append(gen_state)\n",
        "        labels.append(gen_label)\n",
        "    \n",
        "    images = np.array(images)\n",
        "#     print(images.shape)\n",
        "    images = images.reshape(bs, 80, 80, 4)\n",
        "#     print(images.shape)\n",
        "    labels = np.array(labels)\n",
        "#     print(labels.shape)\n",
        "    labels = labels.reshape(bs, 8)\n",
        "#     print(labels.shape)\n",
        "    # if the data augmentation object is not None, apply it\n",
        "    if aug is not None:\n",
        "      (images, labels) = next(aug.flow(images, labels, batch_size=bs))\n",
        "    \n",
        "    return images, labels, state, state_labels\n",
        "  \n",
        "def gen_batch_single_frame(file, bs, D, mode):\n",
        "    \n",
        "    images=[]\n",
        "    labels=[]\n",
        "\n",
        "    while len(images) < bs:  \n",
        "        \n",
        "        current = file.readline().rstrip()\n",
        "\n",
        "        #if reach end of the file start again\n",
        "        if current == \"\":\n",
        "            \n",
        "            file.seek(0)\n",
        "            current = file.readline().rstrip()\n",
        "            \n",
        "            if mode == \"eval\":\n",
        "                break\n",
        "            \n",
        "        data_list = current.split(',')\n",
        "#         if len(images) == 10:\n",
        "#             print(data_list)\n",
        "\n",
        "        data_list = [x for x in data_list if str(x) != 'nan']\n",
        "\n",
        "#         print('no. in batch: ', len(images))\n",
        "\n",
        "#         if len(images) == 10:\n",
        "#             print(data_list)\n",
        "#               print(len(data_list))\n",
        "\n",
        "        image_data, state_label = get_image_from_coords(data_list)\n",
        "        \n",
        "        # store the transition in D\n",
        "        if D is not None:\n",
        "            D.append((state, state_labels))\n",
        "            if len(D) > REPLAY_MEMORY:\n",
        "                D.popleft()\n",
        "#             print(len(D))\n",
        "        \n",
        "            # training with experience replay\n",
        "            miniBatch = random.sample(D,1)\n",
        "            gen_state, gen_label = zip(*miniBatch)\n",
        "            images.append(gen_state)\n",
        "            labels.append(gen_label)\n",
        "        else:\n",
        "            images.append(image_data)\n",
        "            labels.append(state_label)\n",
        "    \n",
        "    images = np.array(images)\n",
        "#     print(images.shape)\n",
        "    images = images.reshape(bs, 80, 80, 1)\n",
        "#     print(images.shape)\n",
        "    labels = np.array(labels)\n",
        "#     print(labels.shape)\n",
        "    labels = labels.reshape(bs, 2)\n",
        "#     print(labels.shape)\n",
        "    # if the data augmentation object is not None, apply it\n",
        "    if aug is not None:\n",
        "      (images, labels) = next(aug.flow(images, labels, batch_size=bs))\n",
        "    \n",
        "    return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oFd4h0qxcNXw",
        "colab": {}
      },
      "source": [
        "\n",
        "'''import numpy as np\n",
        "import sys\n",
        "import random\n",
        "import pygame\n",
        "import flappy_bird_utils\n",
        "import pygame.surfarray as surfarray\n",
        "from pygame.locals import *\n",
        "from itertools import cycle'''\n",
        "\n",
        "def csv_image_generator(filepath, bs, mode=\"train\", aug=None, gen_stacked=False, useExperienceReplay=False):\n",
        "\n",
        "    file = open(filepath,\"r\")\n",
        "    \n",
        "    maxCount = 100\n",
        "    count = maxCount\n",
        "       \n",
        "    # initialize state\n",
        "    current = file.readline().rstrip()\n",
        "  \n",
        "    data_list = current.split(',')\n",
        " \n",
        "#     print(data_list)\n",
        "    data_list = [x for x in data_list if str(x) != 'nan']          \n",
        "#     print(data_list)\n",
        "\n",
        "    image_data, state_label = get_image_from_coords(data_list)\n",
        "        \n",
        "#     print(type(image_data))\n",
        "#     print(\"image_data\" ,image_data)\n",
        "#     print(\"image_data.shape: \", image_data.shape)\n",
        "#     IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "#     plt.show()\n",
        "  \n",
        "    image_data = image_data.reshape(80, 80)\n",
        "#     print(image_data.shape)\n",
        "\n",
        "    if gen_stacked:\n",
        "\n",
        "        state = np.stack((image_data, image_data, image_data, image_data), axis=2)\n",
        "        print(state.shape)\n",
        "        state = state.reshape(1, state.shape[0], state.shape[1], state.shape[2])  #1*80*80*4\n",
        "        state_label = np.array(state_label)\n",
        "        state_labels = np.stack((state_label, state_label, state_label, state_label), axis=0)\n",
        "#         print(state_labels)\n",
        "        state_labels = state_labels.flatten()\n",
        "#         print(state_labels)    \n",
        "    \n",
        "        # store the previous observations in replay memory\n",
        "        D = deque()\n",
        "        D.append((state, state_label)) \n",
        "\n",
        "        while True:\n",
        "          \n",
        "#             count -= 1\n",
        "#             if count > 1:\n",
        "#                 continue\n",
        "#             if count == 0:\n",
        "#                 break;\n",
        "#             print('count: ', count)\n",
        "            \n",
        "            images, labels, state, state_labels = gen_batch_stacked_frames(file, state, state_labels, bs, D, mode)\n",
        "        \n",
        "            # yield the batch to the calling function\n",
        "#             print(images.shape)\n",
        "#             print(labels.shape)\n",
        "            \n",
        "            yield (images, labels)    \n",
        "        \n",
        "    elif useExperienceReplay:    \n",
        "\n",
        "        # store the previous observations in replay memory\n",
        "        D = deque()\n",
        "        D.append((image_data, state_labels)) \n",
        "\n",
        "        while True:\n",
        "          \n",
        "#             count -= 1\n",
        "#             if count > 1:\n",
        "#                 continue\n",
        "#             if count == 0:\n",
        "#                 break;\n",
        "#             print('count: ', count)\n",
        "            \n",
        "            images, labels = gen_batch_single_frame(file, bs, D, mode)\n",
        "        \n",
        "            # yield the batch to the calling function\n",
        "#             print(images.shape)\n",
        "#             print(labels.shape)\n",
        "            \n",
        "            yield (images, labels)   \n",
        "    \n",
        "    else:\n",
        "      \n",
        "        while True:\n",
        "          \n",
        "#             count -= 1\n",
        "#             if count > 1:\n",
        "#                 continue\n",
        "#             if count == 0:\n",
        "#                 break;\n",
        "#             print('count: ', count)\n",
        "            \n",
        "            images, labels = gen_batch_single_frame(file, bs, D=None, mode=mode)\n",
        "        \n",
        "            # yield the batch to the calling function\n",
        "#             print(images.shape)\n",
        "#             print(labels.shape)\n",
        "            \n",
        "            yield (images, labels)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RoY9XL6ERYaG",
        "outputId": "f90d7193-c87d-4dd7-bf21-b39ee1a6f597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# file= \"data.csv\" #file path or a file in the current folder\n",
        "# csv_image_generator(file, 8, mode=\"train\", aug=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object csv_image_generator at 0x7f6805691990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPzIfBewKg4S",
        "colab_type": "code",
        "outputId": "37fc81cf-c5c4-4be1-b0ce-1c415d939330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "!pip install Keras-CoordConv\n",
        "# !pip install pyimagesearch"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Keras-CoordConv\n",
            "  Downloading https://files.pythonhosted.org/packages/d2/aa/4bbce2d9645afa6523df8d8a53832d8999367e8f89297a43382146814f15/Keras_CoordConv-0.6.tar.gz\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from Keras-CoordConv) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.16.5)\n",
            "Building wheels for collected packages: Keras-CoordConv\n",
            "  Building wheel for Keras-CoordConv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Keras-CoordConv: filename=Keras_CoordConv-0.6-cp36-none-any.whl size=7578 sha256=5043e19223d98fbc290b0b82093df23ebd363942bb566219759000a55dd96dd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/32/98/8eeb612bb1bee30a9ee99ff406da961bcfef37fc7cf14f4120\n",
            "Successfully built Keras-CoordConv\n",
            "Installing collected packages: Keras-CoordConv\n",
            "Successfully installed Keras-CoordConv-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0keTKP-0OZUO",
        "colab_type": "code",
        "outputId": "d0a97e61-060a-4412-db04-258362158381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!rm trainData.csv\n",
        "!rm testData.csv\n",
        "!ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "animation1.gif\tdata.txt     model.h5\t\t    qlearn.py\n",
            "assets\t\tgame\t     model.json\t\t    qlearn_ray.py\n",
            "data.csv\t__init__.py  qlearn_loc_and_ray.py  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bd04oRFiRKJc",
        "outputId": "8ab6f9c1-6fc2-4f4d-84f6-1f3964334fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "# USAGE\n",
        "# python train.py\n",
        "\n",
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "import sys\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.initializers import normal, identity\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from tensorflow.keras.layers import Conv2D, Reshape\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.backend import epsilon\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from Keras_CoordConv.coord import CoordinateChannel2D\n",
        "# from coord import CoordinateChannel2D\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "img_rows , img_cols = 80, 80\n",
        "#Convert image into Black and white\n",
        "\n",
        "use_single_frame = True\n",
        "use_4_frames = False #If We stack 4 frames for model input\n",
        "\n",
        "if use_single_frame == True:\n",
        "    img_channels = 1 #single frame for model input\n",
        "    out_shape = 2 #2 ouptut neurons for single x, y player coordinate for output\n",
        "else:\n",
        "    img_channels = 4 #stack 4 frames for model input\n",
        "    out_shape = 8 #8 output neurons for 4 pairs of x, y player coordinate for output\n",
        "    \n",
        "usingSimpleCNN = 1\n",
        "usingSimpleCoordConv = 0\n",
        "usingMobileNetV2Localizer = 0\n",
        "\n",
        "gen_stacked = False\n",
        "useExperienceReplay = False\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "def buildSimpleCNN():\n",
        "    print(\"Now we build the model\")\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(32, 8, 8, subsample=(4,4), border_mode='same', input_shape=(img_cols,img_rows,img_channels)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(64, 4, 4, subsample=(2,2), border_mode='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(64, 3, 3, subsample=(1,1), border_mode='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(out_shape))\n",
        "   \n",
        "    adam = Adam(lr=1e-6)\n",
        "    model.compile(loss='mse',optimizer=adam)\n",
        "    print(\"We finish building the model\")\n",
        "    return model\n",
        "\n",
        "def create_COORDCONV_Simple_CNN():\n",
        "    print(\"Now we build the model\")\n",
        "    ip = Input(shape=(img_rows,img_cols,img_channels))\n",
        "    x = CoordinateChannel2D()(ip)\n",
        "    x = Convolution2D(32, 8, 8, subsample=(4,4), border_mode='same')\n",
        "    x = Activation('relu')\n",
        "    x = CoordinateChannel2D()(x)\n",
        "    x = Convolution2D(64, 4, 4, subsample=(2,2), border_mode='same')\n",
        "    x = Activation('relu')\n",
        "    x = CoordinateChannel2D()(x)\n",
        "    x = Convolution2D(64, 3, 3, subsample=(1,1), border_mode='same')\n",
        "    x = Activation('relu')\n",
        "    x = Flatten()\n",
        "    x = Dense(512)\n",
        "    x = Activation('relu')\n",
        "    x = Dense(out_shape)\n",
        "    model = keras.Model(inputs=ip, outputs=x)\n",
        "    adam = Adam(lr=1e-6)\n",
        "    model.compile(loss='mse',optimizer=adam)\n",
        "    return model\n",
        "\n",
        "\"\"\"\n",
        "# prior to first conv\n",
        "ip = Input(shape=(64, 64, 2))\n",
        "x = CoordinateChannel2D()(ip)\n",
        "x = Conv2D(...)(x)  # This defines the `CoordConv` from the paper.\n",
        "...\n",
        "x = CoordinateChannel2D(use_radius=True)(x)\n",
        "x = Conv2D(...)(x)  # This adds the 3rd channel for the radius.\n",
        "\"\"\"\n",
        "def create_MobileNetV2_model(trainable=False):\n",
        "    model = MobileNetV2(input_shape=(img_channels,img_rows,img_cols), include_top=False)\n",
        "\n",
        "    # to freeze layers\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    x = model.layers[-1].output\n",
        "    x = Conv2D(4, kernel_size=3, name=\"coords\")(x)\n",
        "    x = Reshape((out_shape,))(x)\n",
        "\n",
        "    model = Model(inputs=model.input, outputs=x)\n",
        "    adam = Adam(lr=1e-6)\n",
        "    model.compile(loss='mse', optimizer=adam)\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_train_test_split():\n",
        "    data = np.genfromtxt('data.csv', delimiter=',')\n",
        "    if use_single_frame and not useExperienceReplay:\n",
        "        data = np.take(data,np.random.rand(data.shape[0]).argsort(),axis=0,out=data)\n",
        "        print('shuffled data')\n",
        "#         data = np.random.shuffle(data)\n",
        "    traintestsplit = np.split(data, [int(4*data.shape[0]/5)])\n",
        "    train = traintestsplit[0]\n",
        "    test = traintestsplit[1]\n",
        "#     print(train[108])\n",
        "    return train, test\n",
        "\n",
        "# initialize the paths to our training and testing CSV files\n",
        "#TRAIN_CSV = \"flowers17_training.csv\"\n",
        "#TEST_CSV = \"flowers17_testing.csv\"\n",
        "\n",
        "TRAIN, TEST = get_train_test_split()\n",
        "\n",
        "# initialize the number of epochs to train for and batch size\n",
        "NUM_EPOCHS = 75\n",
        "BS = 32\n",
        "\n",
        "# initialize the total number of training and testing image\n",
        "NUM_TRAIN_IMAGES = 0\n",
        "NUM_TEST_IMAGES = 0\n",
        "\n",
        "# open the training CSV file, then initialize the unique set of class\n",
        "# labels in the dataset along with the testing labels\n",
        "#f = open(TRAIN_CSV, \"r\")\n",
        "labels = set()\n",
        "testLabels = []\n",
        "\n",
        "'''\n",
        "# loop over all rows of the CSV file\n",
        "for row in TRAIN:\n",
        "\t# extract the class label, update the labels list, and increment\n",
        "\t# the total number of training images\n",
        "\tlabel = line.strip().split(\",\")[0]\n",
        "\tlabels.add(label)\n",
        "\tNUM_TRAIN_IMAGES += 1\n",
        "\n",
        "# close the training CSV file and open the testing CSV file\n",
        "f.close()\n",
        "f = open(TEST_CSV, \"r\")\n",
        "\n",
        "# loop over the lines in the testing file\n",
        "for row in TEST:\n",
        "\t# extract the class label, update the test labels list, and\n",
        "\t# increment the total number of testing images\n",
        "\tlabel = line.strip().split(\",\")[0]\n",
        "\ttestLabels.append(label)\n",
        "\tNUM_TEST_IMAGES += 1\n",
        "\n",
        "# close the testing CSV file\n",
        "f.close()\n",
        "'''\n",
        "\n",
        "trainLabels = TRAIN[:,1:3]\n",
        "trainData = TRAIN[:,:]\n",
        "np.savetxt('trainData.csv', trainData, delimiter=',')\n",
        "NUM_TRAIN_IMAGES = trainData.shape[0]\n",
        "\n",
        "print('num train images: ', NUM_TRAIN_IMAGES)\n",
        "\n",
        "# file = open('trainData.csv', \"r\")\n",
        "\n",
        "# for i in range(101):\n",
        "#     current = file.readline().rstrip()\n",
        "# data_list = current.split(',')\n",
        "# print(data_list)\n",
        "# data_list = [x for x in data_list if str(x) != 'nan']          \n",
        "# print(data_list)\n",
        "# image_data, state_label = get_image_from_coords(data_list)\n",
        "# file.close()\n",
        "# # print(type(image_data))\n",
        "# # print(\"image_data\" ,image_data)\n",
        "\n",
        "# image_data = image_data.reshape(80,80)\n",
        "# print(\"image_data.shape: \", image_data.shape)\n",
        "\n",
        "# IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "testLabels = TEST[:,1:3]\n",
        "testData = TEST[:,:]\n",
        "np.savetxt('testData.csv', testData, delimiter=',')\n",
        "NUM_TEST_IMAGES = testData.shape[0]\n",
        "\n",
        "print('num test images: ', NUM_TEST_IMAGES)\n",
        "\n",
        "# create the label binarizer for one-hot encoding labels, then encode\n",
        "# the testing labels\n",
        "# lb = LabelBinarizer()\n",
        "# lb.fit(list(trainLabels))\n",
        "# testLabels = lb.transform(testLabels)\n",
        "\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2, fill_mode=\"nearest\")\n",
        "\n",
        "# initialize both the training and testing image generators\n",
        "trainGen = csv_image_generator('trainData.csv', BS, #lb,\n",
        "    mode=\"train\", aug=aug,\n",
        "    gen_stacked=gen_stacked, useExperienceReplay=useExperienceReplay\n",
        "  )\n",
        "\n",
        "testGen = csv_image_generator('testData.csv', BS, #lb,\n",
        "    mode=\"train\", aug=None,\n",
        "    gen_stacked=gen_stacked, useExperienceReplay=useExperienceReplay\n",
        "  )\n",
        "\n",
        "# initialize our Keras model and compile it\n",
        "if usingSimpleCNN:\n",
        "    model = buildSimpleCNN()\n",
        "elif usingSimpleCoordConv:\n",
        "    model = create_COORDCONV_Simple_CNN()    \n",
        "elif usingMobileNetV2Localizer:\n",
        "    model = create_MobileNetV2_model()\n",
        "\n",
        "# train the network\n",
        "print(\"[INFO] training w/ generator...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=math.ceil(NUM_TRAIN_IMAGES / BS),\n",
        "\tvalidation_data=testGen,\n",
        "\tvalidation_steps=math.ceil(NUM_TEST_IMAGES / BS),\n",
        "\tepochs=NUM_EPOCHS)\n",
        "\n",
        "# re-initialize our testing data generator, this time for evaluating\n",
        "testGen = csv_image_generator(TEST_CSV, BS, #lb,\n",
        "    mode=\"eval\", aug=None,\n",
        "    gen_stacked=gen_stacked, useExperienceReplay=useExperienceReplay\n",
        "  )\n",
        "\n",
        "# make predictions on the testing images, finding the index of the\n",
        "# label with the corresponding largest predicted probability\n",
        "predIdxs = model.predict_generator(testGen,\n",
        "\tsteps=(NUM_TEST_IMAGES // BS) + 1)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(\"[INFO] evaluating network...\")\n",
        "print(classification_report(testLabels.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=lb.classes_))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = NUM_EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"plot.png\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shuffled data\n",
            "num train images:  80008\n",
            "num test images:  20003\n",
            "Now we build the model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (8, 8), input_shape=(80, 80, 1..., strides=(4, 4), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "We finish building the model\n",
            "[INFO] training w/ generator...\n",
            "Epoch 1/75\n",
            "  29/2501 [..............................] - ETA: 49:39 - loss: 17319.4990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-fd73728906e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestGen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_TEST_IMAGES\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m \tepochs=NUM_EPOCHS)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;31m# re-initialize our testing data generator, this time for evaluating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}