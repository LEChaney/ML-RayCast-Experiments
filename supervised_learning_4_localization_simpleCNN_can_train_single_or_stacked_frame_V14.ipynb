{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Image_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:tensorflow113]",
      "language": "python",
      "name": "conda-env-tensorflow113-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEChaney/ML-RayCast-Experiments/blob/master/supervised_learning_4_localization_simpleCNN_can_train_single_or_stacked_frame_V14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jw1arH2vxVXK",
        "outputId": "51cff456-201b-41c7-c12e-d5db7f7f36cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "!git clone https://github.com/LEChaney/ML-RayCast-Experiments\n",
        "%cd ML-RayCast-Experiments\n",
        "%pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML-RayCast-Experiments'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 518 (delta 18), reused 4 (delta 2), pack-reused 484\u001b[K\n",
            "Receiving objects: 100% (518/518), 79.89 MiB | 9.67 MiB/s, done.\n",
            "Resolving deltas: 100% (293/293), done.\n",
            "/content/ML-RayCast-Experiments\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ML-RayCast-Experiments'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nR2rN0ieyYQ5",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "def rotate(image_path):\n",
        "    \"\"\"\n",
        "    Rotate the given photo the amount of given degreesk, show it and save it\n",
        "    @param image_path: The path to the image to edit\n",
        "    @param degrees_to_rotate: The number of degrees to rotate the image\n",
        "    @param saved_location: Path to save the cropped image\n",
        "    \"\"\"\n",
        "    degrees_to_rotate = 180\n",
        "    image_obj = Image.open(image_path)\n",
        "    rotated_image = image_obj.rotate(degrees_to_rotate)\n",
        "    rotated_image.save(\"000.png\")\n",
        "    im = cv2.imread(\"000.png\")\n",
        "    #plt.imshow(im)\n",
        "    #plt.show()\n",
        "    return im\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BqsexcF4qXfE",
        "outputId": "6591a7d2-2ec7-4ce0-edfb-76091d7df84b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "os.environ['SDL_VIDEODRIVER']='dummy'\n",
        "file_directory = os.getcwd()\n",
        "os.chdir(\"/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master\")\n",
        "print(os.getcwd())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iY7nyqTkNMef",
        "outputId": "4a8ae47c-4957-49ae-b386-ff632262babd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import sys\n",
        "#sys.path.pop(1)\n",
        "sys.path.insert(1,\"/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master/game\")\n",
        "print(sys.path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master/game', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWn6wAeaI8DD",
        "colab_type": "code",
        "outputId": "cabb2866-a749-4d82-f1ba-6d4efee1fa39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!pwd\n",
        "!ls /content/gdrive/'Shared drives'/'COMPSCI 760'/data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master\n",
            "'Copy of FlappyBirdData.zip'   data.txt\t\t'The explaination of data.gdoc'\n",
            " data_new_1st_million.txt      testData.csv\t trainData.csv\n",
            " data_new.txt\t\t       testData.gsheet\t trainData.gsheet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F-j-vysiwaMd",
        "outputId": "1f410f7a-1662-4e36-dfe7-5dae7cd4761c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "%pip install pygame"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-1.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GGMYTHT4OLy4",
        "outputId": "9b4145b9-37cf-4d5a-9c3d-336f4d3d71fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "sys.path.append(\"game/\")\n",
        "import wrapped_flappy_bird as game\n",
        "import numpy as np\n",
        "import flappy_bird_utils\n",
        "import cv2\n",
        "import sys\n",
        "import random\n",
        "import pygame\n",
        "import pygame.surfarray as surfarray\n",
        "from pygame.locals import *\n",
        "from itertools import cycle\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "#from cStringIO import StringIO\n",
        "import IPython.display\n",
        "\n",
        "import argparse\n",
        "import skimage as skimage\n",
        "from skimage import transform, color, exposure\n",
        "from skimage.transform import rotate\n",
        "from skimage.viewer import ImageViewer\n",
        "import json\n",
        "\n",
        "from collections import deque"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 1.9.6\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/viewer/__init__.py:6: UserWarning: Viewer requires Qt\n",
            "  warn('Viewer requires Qt')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "epVQmcWzpGRU",
        "outputId": "40937d3d-ac24-40ba-d68e-de760b80ab2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "GAME = 'bird' # the name of the game being played for log files\n",
        "CONFIG = 'nothreshold'\n",
        "ACTIONS = 2 # number of valid actions\n",
        "GAMMA = 0.99 # decay rate of past observations\n",
        "OBSERVATION = 2 #3200. # timesteps to observe before training\n",
        "EXPLORE = 3000000. # frames over which to anneal epsilon\n",
        "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
        "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
        "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
        "BATCH = 32 # size of minibatch\n",
        "FRAME_PER_ACTION = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "FPS = 30\n",
        "SCREENWIDTH  = 288\n",
        "SCREENHEIGHT = 512\n",
        "\n",
        "pygame.init()\n",
        "pygame.display.init()\n",
        "pygame.display.set_mode((1, 1))\n",
        "FPSCLOCK = pygame.time.Clock()\n",
        "SCREEN = pygame.Surface((SCREENWIDTH, SCREENHEIGHT)).convert_alpha()\n",
        "pygame.display.set_caption('Flappy Bird')\n",
        "\n",
        "IMAGES, SOUNDS, HITMASKS = flappy_bird_utils.load()\n",
        "PIPEGAPSIZE = 100 # gap between upper and lower part of pipe\n",
        "BASEY = SCREENHEIGHT * 0.79\n",
        "\n",
        "PLAYER_WIDTH = IMAGES['player'][0].get_width()\n",
        "PLAYER_HEIGHT = IMAGES['player'][0].get_height()\n",
        "PIPE_WIDTH = IMAGES['pipe'][0].get_width()\n",
        "PIPE_HEIGHT = IMAGES['pipe'][0].get_height()\n",
        "BACKGROUND_WIDTH = IMAGES['background'].get_width()\n",
        "\n",
        "PLAYER_INDEX_GEN = cycle([0, 1, 2, 1])\n",
        "\n",
        "img_rows , img_cols = 80, 80\n",
        "#Convert image into Black and white\n",
        "img_channels = 4 #We stack 4 frames\n",
        "\n",
        "game_state = game.GameState()\n",
        "do_nothing = np.zeros(ACTIONS)\n",
        "do_nothing[0] = 1\n",
        "game_state.frame_step(do_nothing)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0, 0, 0]]], dtype=uint8), 0.1, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLkjBOh4Y4FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image_from_coords(data_list, num_channels=1, img_rows=80):\n",
        "  \n",
        "    CaseNo = int(float(data_list[0]))\n",
        "    assert not np.any(np.isnan(np.array(CaseNo)))\n",
        "    game_state.playerx = int(float(data_list[1]))# + SCREENWIDTH /2)\n",
        "    game_state.playery = int(float(data_list[2]))# + SCREENWIDTH /2)\n",
        "    game_state.playerIndex = int(float(data_list[3]))        \n",
        "\n",
        "    game_state.upperPipes = []\n",
        "    game_state.lowerPipes = []\n",
        "\n",
        "    for i in range(4,len(data_list),4):\n",
        "\n",
        "        newPipe = game.getRandomPipe()\n",
        "        game_state.upperPipes.append(newPipe[0])\n",
        "        game_state.upperPipes[int((i-4)/4)]['x'] = int(float(data_list[i]))# + SCREENWIDTH /2)\n",
        "        game_state.upperPipes[int((i-4)/4)]['y'] = int(float(data_list[i+1]))# + SCREENWIDTH /2)\n",
        "\n",
        "        game_state.lowerPipes.append(newPipe[1])\n",
        "        game_state.lowerPipes[int((i-4)/4)]['x'] = int(float(data_list[i+2]))# + SCREENWIDTH /2)\n",
        "#         print(data_list)\n",
        "#         print(len(data_list))\n",
        "#         print(i+3)\n",
        "        game_state.lowerPipes[int((i-4)/4)]['y'] = int(float(data_list[i+3]))# + SCREENWIDTH /2)\n",
        "\n",
        "    # draw sprites\n",
        "    SCREEN.blit(IMAGES['background'], (0,0))\n",
        "\n",
        "    for uPipe, lPipe in zip(game_state.upperPipes, game_state.lowerPipes):\n",
        "        SCREEN.blit(IMAGES['pipe'][0], (uPipe['x'], uPipe['y']))\n",
        "        SCREEN.blit(IMAGES['pipe'][1], (lPipe['x'], lPipe['y']))\n",
        "\n",
        "    SCREEN.blit(IMAGES['base'], (game_state.basex, BASEY))\n",
        "    # print score so player overlaps the score\n",
        "    # showScore(self.score)\n",
        "    SCREEN.blit(IMAGES['player'][game_state.playerIndex],\n",
        "                (game_state.playerx, game_state.playery))\n",
        "\n",
        "    image_data = pygame.surfarray.array3d(SCREEN)\n",
        "#     print('SCREEN image size: ', image_data.shape)\n",
        "#     IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "#     plt.show()\n",
        "    if num_channels == 1:\n",
        "        image_data = skimage.color.rgb2gray(image_data) #comment out if using single frame prediction\n",
        "    \n",
        "    image_data = skimage.transform.resize(image_data,(img_rows,img_rows))\n",
        "#     print(image_data.shape)\n",
        "    if np.any(image_data):\n",
        "        image_data = skimage.exposure.rescale_intensity(image_data, out_range=(0,255))\n",
        "    else:\n",
        "        print('ERROR: completely black image')\n",
        "#     print(image_data.shape)\n",
        "    if num_channels == 1:\n",
        "        image_data = image_data / 255.0\n",
        "    elif num_channels == 3:\n",
        "        image_data = preprocess_input(image_data)\n",
        "#         print('preprocessed data')\n",
        "    image_data = image_data.reshape(1, image_data.shape[0], image_data.shape[1], num_channels) #1x80x80x1\n",
        "\n",
        "    label = np.array([game_state.playerx, game_state.playery])\n",
        "    \n",
        "#     #print(type(image_data))\n",
        "#     print(\"image_data\" ,image_data)\n",
        "#     print(\"image_data.shape: \", image_data.shape)\n",
        "#     IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "#     plt.show()\n",
        "#     print(image_data.shape)\n",
        "    return image_data, label\n",
        "\n",
        "def gen_batch_stacked_frames(file, state, stacked_state_label, bs, D, mode, img_rows=80):\n",
        "    \n",
        "    images=[]\n",
        "    labels=[]\n",
        "\n",
        "    while len(images) < bs:  \n",
        "        \n",
        "        current = file.readline().rstrip()\n",
        "\n",
        "        #if reach end of the file start again\n",
        "        if current == \"\":\n",
        "            \n",
        "            file.seek(0)\n",
        "\n",
        "            current = file.readline().rstrip()\n",
        "            \n",
        "            if mode == \"eval\":\n",
        "                break\n",
        "            \n",
        "            data_list = current.split(',')\n",
        "            data_list = [x for x in data_list if str(x) != 'nan']\n",
        "  \n",
        "            image_data, state_label = get_image_from_coords(data_list, img_rows=img_rows)\n",
        "            if not np.any(image_data):\n",
        "                continue\n",
        "            image_data = image_data.reshape(img_rows, img_rows)\n",
        "            state = np.stack((image_data, image_data, image_data, image_data), axis=2)\n",
        "            state = state.reshape(1, state.shape[0], state.shape[1], state.shape[2])  #1*80*80*4\n",
        "#             state_label = np.array(state_label)\n",
        "            stacked_state_label = np.concatenate((state_label, state_label, state_label, state_label), axis=0).flatten()\n",
        "#             print(stacked_state_label)\n",
        "#             stacked_state_label = stacked_state_label.flatten()\n",
        "#             print('stacked_state_label: ', stacked_state_label) \n",
        "            #state = state.reshape(state.shape[0],)\n",
        "            \n",
        "            # store the transition in D\n",
        "            D.append((state, stacked_state_label))   \n",
        "            \n",
        "#             if current[0] == \"-\":\n",
        "#                 continue\n",
        "        else:   \n",
        "            \n",
        "            data_list = current.split(',')\n",
        "#             if len(images) == 10:\n",
        "#                 print(data_list)\n",
        "            \n",
        "            data_list = [x for x in data_list if str(x) != 'nan']\n",
        "            \n",
        "#             print('no. in batch: ', len(images))\n",
        "            \n",
        "#             if len(images) == 10:\n",
        "#                 print(data_list)\n",
        "#                   print(len(data_list))\n",
        "            \n",
        "            image_data, state_label = get_image_from_coords(data_list)\n",
        "            if not np.any(image_data):\n",
        "                continue\n",
        "    #             state.append(image_data)\n",
        "    #             state_labels.append(state_label)\n",
        "#             print(state.shape)\n",
        "#             print(image_data.shape)\n",
        "            state = np.append(image_data, state[:, :, :, :3], axis=3)\n",
        "#             stacked_state_label = np.append(stacked_state_label, stacked_state_label[:6]).flatten()\n",
        "#             print(state_label.shape)\n",
        "#             print(stacked_state_label.shape)\n",
        "            stacked_state_label = np.concatenate((state_label, stacked_state_label[:6]), axis=0).flatten()\n",
        "#             print(stacked_state_label)\n",
        "#             stacked_state_label = stacked_state_label.flatten()\n",
        "#             print('stacked_state_label.shape: ', stacked_state_label.shape) \n",
        "            #state = np.array(state)\n",
        "            #state = state.reshape(state.shape[0],)\n",
        "        \n",
        "            # store the transition in D\n",
        "            D.append((state, stacked_state_label))\n",
        "        \n",
        "        if len(D) > REPLAY_MEMORY:\n",
        "            D.popleft()\n",
        "#         print(len(D))\n",
        "\n",
        "        # training with experience replay\n",
        "        miniBatch = random.sample(D,1)\n",
        "        gen_state, gen_label = zip(*miniBatch)\n",
        "#         print('gen_state: ', gen_state[0])\n",
        "#         print('gen_label: ', gen_label[0])\n",
        "        images.append(gen_state[0])\n",
        "#         print(gen_label[0])\n",
        "        labels.append(gen_label[0])\n",
        "#         print('len(labels): ', len(labels))\n",
        "    \n",
        "    images = np.array(images)\n",
        "#     print(images.shape)\n",
        "    images = images.reshape(bs, img_rows, img_rows, 4)\n",
        "#     print(images.shape)\n",
        "#     print('labels: ', labels)\n",
        "    labels = np.array(labels)\n",
        "#     print('labels: ', labels)\n",
        "#     print('labels.shape: ', labels.shape)\n",
        "    labels = labels.reshape(bs, 8)\n",
        "#     print('labels.shape: ', labels.shape)\n",
        "    # if the data augmentation object is not None, apply it\n",
        "    if aug is not None:\n",
        "      (images, labels) = next(aug.flow(images, labels, batch_size=bs))\n",
        "    \n",
        "    return images, labels, state, stacked_state_label\n",
        "  \n",
        "def gen_batch_single_frame(file, bs, D, mode, num_channels, img_rows=80):\n",
        "    \n",
        "    images=[]\n",
        "    labels=[]\n",
        "\n",
        "    while len(images) < bs:  \n",
        "        \n",
        "        current = file.readline().rstrip()\n",
        "\n",
        "        #if reach end of the file start again\n",
        "        if current == \"\":\n",
        "            \n",
        "            file.seek(0)\n",
        "            current = file.readline().rstrip()\n",
        "            \n",
        "            if mode == \"eval\":\n",
        "                break\n",
        "            \n",
        "        data_list = current.split(',')\n",
        "#         if len(images) == 10:\n",
        "#             print(data_list)\n",
        "\n",
        "        data_list = [x for x in data_list if str(x) != 'nan']\n",
        "\n",
        "#         print('no. in batch: ', len(images))\n",
        "\n",
        "#         if len(images) == 10:\n",
        "#             print(data_list)\n",
        "#               print(len(data_list))\n",
        "\n",
        "        image_data, state_label = get_image_from_coords(data_list, num_channels=num_channels, img_rows=img_rows)\n",
        "        if not np.any(image_data):\n",
        "            continue\n",
        "#         print(image_data.shape)\n",
        "        # store the transition in D\n",
        "        if D is not None:\n",
        "            D.append((state, state_label))\n",
        "            if len(D) > REPLAY_MEMORY:\n",
        "                D.popleft()\n",
        "#             print(len(D))\n",
        "        \n",
        "            # training with experience replay\n",
        "            miniBatch = random.sample(D,1)\n",
        "            gen_state, gen_label = zip(*miniBatch)\n",
        "            assert not np.any(np.isnan(gen_state))\n",
        "            assert not np.any(np.isnan(gen_label))\n",
        "            images.append(gen_state)\n",
        "            labels.append(gen_label)\n",
        "        else:\n",
        "            images.append(image_data)\n",
        "            labels.append(state_label)\n",
        "    \n",
        "    images = np.array(images)\n",
        "#     print(images.shape)\n",
        "    images = images.reshape(bs, img_rows, img_rows, num_channels)\n",
        "#     print(images.shape)\n",
        "    labels = np.array(labels)\n",
        "#     print(labels.shape)\n",
        "    labels = labels.reshape(bs, 2)\n",
        "#     print(labels.shape)\n",
        "    # if the data augmentation object is not None, apply it\n",
        "    if aug is not None:\n",
        "      (images, labels) = next(aug.flow(images, labels, batch_size=bs))\n",
        "    \n",
        "    return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oFd4h0qxcNXw",
        "colab": {}
      },
      "source": [
        "\n",
        "'''import numpy as np\n",
        "import sys\n",
        "import random\n",
        "import pygame\n",
        "import flappy_bird_utils\n",
        "import pygame.surfarray as surfarray\n",
        "from pygame.locals import *\n",
        "from itertools import cycle'''\n",
        "\n",
        "def csv_image_generator(filepath, bs, mode=\"train\", aug=None, use_4_frames=False, useExperienceReplay=False, num_channels=1, img_rows=80):\n",
        "\n",
        "    file = open(filepath,\"r\")\n",
        "    \n",
        "    maxCount = 100\n",
        "    count = maxCount\n",
        "       \n",
        "    # initialize state\n",
        "    current = file.readline().rstrip()\n",
        "  \n",
        "    data_list = current.split(',')\n",
        "\n",
        "#     print(data_list)\n",
        "    data_list = [x for x in data_list if str(x) != 'nan']          \n",
        "#     print(data_list)\n",
        "\n",
        "    image_data, state_label = get_image_from_coords(data_list, num_channels=num_channels, img_rows=img_rows)\n",
        "#     print(image_data.shape)\n",
        "#     print(type(image_data))\n",
        "#     print(\"image_data\" ,image_data)\n",
        "#     print(\"image_data.shape: \", image_data.shape)\n",
        "#     IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "#     plt.show()\n",
        "    if num_channels == 3:\n",
        "        image_data = image_data.reshape(img_rows, img_rows, num_channels)\n",
        "    elif num_channels == 1:\n",
        "        image_data = image_data.reshape(img_rows, img_rows)\n",
        "#     print(image_data.shape)\n",
        "  \n",
        "    if use_4_frames:\n",
        "\n",
        "        state = np.stack((image_data, image_data, image_data, image_data), axis=2)\n",
        "  #         print(state.shape)\n",
        "        state = state.reshape(1, state.shape[0], state.shape[1], state.shape[2])  #1*img_rows*img_rows*4\n",
        "        stacked_state_label = np.concatenate((state_label, state_label, state_label, state_label), axis=0).flatten()\n",
        "#         print('stacked_state_label first: ', stacked_state_label)\n",
        "#         stacked_state_label = stacked_state_label.flatten()\n",
        "        print('stacked_state_label first flattened: ', stacked_state_label)    \n",
        "\n",
        "        # store the previous observations in replay memory\n",
        "        D = deque()\n",
        "        D.append((state, stacked_state_label)) \n",
        "\n",
        "        while True:\n",
        "\n",
        "  #             count -= 1\n",
        "  #             if count > 1:\n",
        "  #                 continue\n",
        "  #             if count == 0:\n",
        "  #                 break;\n",
        "  #             print('count: ', count)\n",
        "\n",
        "            images, labels, state, stacked_state_label = gen_batch_stacked_frames(file, state, stacked_state_label, bs, D, mode, img_rows)\n",
        "\n",
        "            # yield the batch to the calling function\n",
        "  #             print(images.shape)\n",
        "  #             print(labels.shape)\n",
        "\n",
        "            yield (images, labels)    \n",
        "\n",
        "    elif useExperienceReplay:    \n",
        "\n",
        "        # store the previous observations in replay memory\n",
        "        D = deque()\n",
        "        D.append((image_data, state_label)) \n",
        "\n",
        "        while True:\n",
        "          \n",
        "#             count -= 1\n",
        "#             if count > 1:\n",
        "#                 continue\n",
        "#             if count == 0:\n",
        "#                 break;\n",
        "#             print('count: ', count)\n",
        "            \n",
        "            images, labels = gen_batch_single_frame(file, bs, D, mode, num_channels, img_rows=img_rows)\n",
        "        \n",
        "            # yield the batch to the calling function\n",
        "#             print(images.shape)\n",
        "#             print(labels.shape)\n",
        "            \n",
        "            yield (images, labels)   \n",
        "    \n",
        "    else:\n",
        "      \n",
        "        while True:\n",
        "          \n",
        "#             count -= 1\n",
        "#             if count > 1:\n",
        "#                 continue\n",
        "#             if count == 0:\n",
        "#                 break;\n",
        "#             print('count: ', count)\n",
        "            \n",
        "            images, labels = gen_batch_single_frame(file, bs, D=None, mode=mode, num_channels=num_channels, img_rows=img_rows)\n",
        "        \n",
        "            # yield the batch to the calling function\n",
        "#             print(images.shape)\n",
        "#             print(labels.shape)\n",
        "            \n",
        "            yield (images, labels)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RoY9XL6ERYaG",
        "outputId": "f90d7193-c87d-4dd7-bf21-b39ee1a6f597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# file= \"data.csv\" #file path or a file in the current folder\n",
        "# csv_image_generator(file, 8, mode=\"train\", aug=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object csv_image_generator at 0x7f6805691990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPzIfBewKg4S",
        "colab_type": "code",
        "outputId": "ca1b86f0-b404-4cde-c45f-9c21ae27c548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "!pip install Keras-CoordConv\n",
        "# !pip install pyimagesearch"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Keras-CoordConv\n",
            "  Downloading https://files.pythonhosted.org/packages/d2/aa/4bbce2d9645afa6523df8d8a53832d8999367e8f89297a43382146814f15/Keras_CoordConv-0.6.tar.gz\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from Keras-CoordConv) (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.16.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (3.13)\n",
            "Building wheels for collected packages: Keras-CoordConv\n",
            "  Building wheel for Keras-CoordConv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Keras-CoordConv: filename=Keras_CoordConv-0.6-cp36-none-any.whl size=7578 sha256=60dc3b290af30f6bf067fb77ca54dda381e5b71d8bcef913146f04a8ae0bf1b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/32/98/8eeb612bb1bee30a9ee99ff406da961bcfef37fc7cf14f4120\n",
            "Successfully built Keras-CoordConv\n",
            "Installing collected packages: Keras-CoordConv\n",
            "Successfully installed Keras-CoordConv-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0keTKP-0OZUO",
        "colab_type": "code",
        "outputId": "9cc74c41-5fa6-4cea-ddcb-25059afca553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "!rm trainData.csv\n",
        "!rm testData.csv\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'trainData.csv': No such file or directory\n",
            "rm: cannot remove 'testData.csv': No such file or directory\n",
            "animation1.gif\tgame\t\t\tmodel.json\t       qlearn_ray.py\n",
            "assets\t\t__init__.py\t\tqlearn_glimpse.py      README.md\n",
            "data.csv\tML-RayCast-Experiments\tqlearn_loc_and_ray.py\n",
            "data.txt\tmodel.h5\t\tqlearn.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bd04oRFiRKJc",
        "outputId": "38559914-c066-4f26-b43d-4ba477196f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# USAGE\n",
        "# python train.py\n",
        "\n",
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "import sys\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.initializers import normal, identity\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Input\n",
        "from keras import Model\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from keras.layers import Conv2D, Reshape\n",
        "from keras.utils import Sequence\n",
        "from keras import backend\n",
        "from keras.backend import epsilon\n",
        "from keras.callbacks import Callback\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from Keras_CoordConv.coord import CoordinateChannel2D\n",
        "# from coord import CoordinateChannel2D\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "img_rows , img_cols = 80, 80\n",
        "#Convert image into Black and white\n",
        "\n",
        "use_single_frame = True\n",
        "use_4_frames = False #If We stack 4 frames for model input\n",
        "use_rgb = True\n",
        "\n",
        "if use_single_frame == True:\n",
        "    if use_rgb:\n",
        "        img_channels = 3 #rgb single frame for model input\n",
        "    else:\n",
        "        img_channels = 1 #greyscale single frame for model input\n",
        "    out_shape = 2 #2 ouptut neurons for single x, y player coordinate for output\n",
        "else:\n",
        "    img_channels = 4 #stack 4 frames for model input\n",
        "    out_shape = 8 #8 output neurons for 4 pairs of x, y player coordinate for output\n",
        "    \n",
        "usingSimpleCNN = 0\n",
        "usingSimpleCoordConv = 0\n",
        "usingMobileNetV2Localizer = 1\n",
        "\n",
        "if usingMobileNetV2Localizer == 1:\n",
        "    backend.set_image_data_format('channels_last')\n",
        "    img_rows, img_cols = 96, 96\n",
        "# print('img_rows: ', img_rows)\n",
        "\n",
        "useExperienceReplay = False\n",
        "\n",
        "MAX_NUM_SAMPLES = 100000\n",
        "\n",
        "np.random.seed(2019)\n",
        "\n",
        "def buildSimpleCNN():\n",
        "    print(\"Now we build the model\")\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(32, 8, 8, subsample=(4,4), border_mode='same', input_shape=(img_cols,img_rows,img_channels)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(64, 4, 4, subsample=(2,2), border_mode='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(64, 3, 3, subsample=(1,1), border_mode='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(out_shape))\n",
        "   \n",
        "    adam = Adam(lr=1e-3)\n",
        "    model.compile(loss='mse',optimizer=adam)\n",
        "    print(\"We finish building the model\")\n",
        "    return model\n",
        "\n",
        "def create_COORDCONV_Simple_CNN():\n",
        "    print(\"Now we build the model\")\n",
        "    ip = Input(shape=(img_rows,img_cols,img_channels))\n",
        "    x = CoordinateChannel2D()(ip)\n",
        "    x = Convolution2D(32, 8, 8, subsample=(4,4), border_mode='same')\n",
        "    x = Activation('relu')\n",
        "    x = CoordinateChannel2D()(x)\n",
        "    x = Convolution2D(64, 4, 4, subsample=(2,2), border_mode='same')\n",
        "    x = Activation('relu')\n",
        "    x = CoordinateChannel2D()(x)\n",
        "    x = Convolution2D(64, 3, 3, subsample=(1,1), border_mode='same')\n",
        "    x = Activation('relu')\n",
        "    x = Flatten()\n",
        "    x = Dense(512)\n",
        "    x = Activation('relu')\n",
        "    x = Dense(out_shape)\n",
        "    model = keras.Model(inputs=ip, outputs=x)\n",
        "    adam = Adam(lr=1e-6)\n",
        "    model.compile(loss='mse',optimizer=adam)\n",
        "    return model\n",
        "\n",
        "\"\"\"\n",
        "# prior to first conv\n",
        "ip = Input(shape=(64, 64, 2))\n",
        "x = CoordinateChannel2D()(ip)\n",
        "x = Conv2D(...)(x)  # This defines the `CoordConv` from the paper.\n",
        "...\n",
        "x = CoordinateChannel2D(use_radius=True)(x)\n",
        "x = Conv2D(...)(x)  # This adds the 3rd channel for the radius.\n",
        "\"\"\"\n",
        "def create_MobileNetV2_model(trainable=False):\n",
        "    input_tensor = Input(shape=(img_rows,img_cols,img_channels)) \n",
        "    model = MobileNetV2(input_tensor=input_tensor, weights='imagenet', input_shape=(img_rows,img_cols,img_channels), include_top=False)\n",
        "\n",
        "    # to freeze layers\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    x = model.layers[-1].output\n",
        "    x = Conv2D(out_shape, kernel_size=3, name=\"coords\")(x)\n",
        "    x = Reshape((out_shape,))(x)\n",
        "\n",
        "    model = Model(inputs=model.input, outputs=x)\n",
        "    adam = Adam(lr=1e-3)\n",
        "    model.compile(loss='mse', optimizer=adam)\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_train_test_split(data_path):\n",
        "    file = open(data_path+'data_new_1st_million.txt','r')\n",
        "    dataList = [line.rstrip().split() for line in file]\n",
        "    dataList = [[int(float(x)) for x in line] for line in dataList]\n",
        "#     print(dataList[0])\n",
        "    data = np.empty((len(dataList),len(max(dataList,key=len))))\n",
        "    data[:,:] = np.nan\n",
        "    for i in range(len(dataList)):\n",
        "        data[i,:len(dataList[i])] = np.array(dataList[i])\n",
        "        assert not np.any(np.isnan(data[i,:len(dataList[i])]))\n",
        "#     print(data[0,:])\n",
        "    file.close()\n",
        "#     data = np.genfromtxt(data_path+'data_new_1st_million.txt', delimiter=' ')\n",
        "    if use_single_frame and not useExperienceReplay:\n",
        "        data = np.take(data,np.random.rand(data.shape[0]).argsort(),axis=0,out=data)\n",
        "        print('shuffled data')\n",
        "#         data = np.random.shuffle(data)\n",
        "    data = data[:MAX_NUM_SAMPLES,:]\n",
        "    traintestsplit = np.split(data, [int(4*data.shape[0]/5)])\n",
        "    train = traintestsplit[0]\n",
        "    test = traintestsplit[1]\n",
        "#     print(train[108])\n",
        "    return train, test\n",
        "\n",
        "class LossHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "\n",
        "    \n",
        "history = LossHistory()    \n",
        "\n",
        "# initialize the paths to our training and testing CSV files\n",
        "#TRAIN_CSV = \"flowers17_training.csv\"\n",
        "#TEST_CSV = \"flowers17_testing.csv\"\n",
        "data_path='/content/gdrive/Shared drives/COMPSCI 760/data/'\n",
        "TRAIN, TEST = get_train_test_split(data_path)\n",
        "\n",
        "# initialize the number of epochs to train for and batch size\n",
        "NUM_EPOCHS = 1#5#75\n",
        "BS = 32\n",
        "\n",
        "# initialize the total number of training and testing image\n",
        "NUM_TRAIN_IMAGES = 0\n",
        "NUM_TEST_IMAGES = 0\n",
        "\n",
        "# open the training CSV file, then initialize the unique set of class\n",
        "# labels in the dataset along with the testing labels\n",
        "#f = open(TRAIN_CSV, \"r\")\n",
        "labels = set()\n",
        "testLabels = []\n",
        "\n",
        "'''\n",
        "# loop over all rows of the CSV file\n",
        "for row in TRAIN:\n",
        "\t# extract the class label, update the labels list, and increment\n",
        "\t# the total number of training images\n",
        "\tlabel = line.strip().split(\",\")[0]\n",
        "\tlabels.add(label)\n",
        "\tNUM_TRAIN_IMAGES += 1\n",
        "\n",
        "# close the training CSV file and open the testing CSV file\n",
        "f.close()\n",
        "f = open(TEST_CSV, \"r\")\n",
        "\n",
        "# loop over the lines in the testing file\n",
        "for row in TEST:\n",
        "\t# extract the class label, update the test labels list, and\n",
        "\t# increment the total number of testing images\n",
        "\tlabel = line.strip().split(\",\")[0]\n",
        "\ttestLabels.append(label)\n",
        "\tNUM_TEST_IMAGES += 1\n",
        "\n",
        "# close the testing CSV file\n",
        "f.close()\n",
        "'''\n",
        "\n",
        "trainLabels = TRAIN[:,1:3]\n",
        "# trainLabels[0] /= SCREENWIDTH\n",
        "# trainLabels[1] /= SCREENHEIGHT\n",
        "trainData = TRAIN[:,:]\n",
        "np.savetxt(data_path+'trainData.csv', trainData, delimiter=',')\n",
        "NUM_TRAIN_IMAGES = trainData.shape[0]\n",
        "\n",
        "print('num train images: ', NUM_TRAIN_IMAGES)\n",
        "\n",
        "# file = open('trainData.csv', \"r\")\n",
        "\n",
        "# for i in range(101):\n",
        "#     current = file.readline().rstrip()\n",
        "# data_list = current.split(',')\n",
        "# print(data_list)\n",
        "# data_list = [x for x in data_list if str(x) != 'nan']          \n",
        "# print(data_list)\n",
        "# image_data, state_label = get_image_from_coords(data_list)\n",
        "# file.close()\n",
        "# # print(type(image_data))\n",
        "# # print(\"image_data\" ,image_data)\n",
        "\n",
        "# image_data = image_data.reshape(80,80)\n",
        "# print(\"image_data.shape: \", image_data.shape)\n",
        "\n",
        "# IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "testLabels = TEST[:,1:3]\n",
        "# testLabels[0] /= SCREENWIDTH\n",
        "# testLabels[1] /= SCREENHEIGHT\n",
        "testData = TEST[:,:]\n",
        "np.savetxt(data_path+'testData.csv', testData, delimiter=',')\n",
        "NUM_TEST_IMAGES = testData.shape[0]\n",
        "\n",
        "print('num test images: ', NUM_TEST_IMAGES)\n",
        "\n",
        "# create the label binarizer for one-hot encoding labels, then encode\n",
        "# the testing labels\n",
        "# lb = LabelBinarizer()\n",
        "# lb.fit(list(trainLabels))\n",
        "# testLabels = lb.transform(testLabels)\n",
        "\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2, fill_mode=\"nearest\")\n",
        "\n",
        "# initialize both the training and testing image generators\n",
        "trainGen = csv_image_generator(data_path+'trainData.csv', BS, #lb,\n",
        "    mode=\"train\", aug=aug,\n",
        "    use_4_frames=use_4_frames, useExperienceReplay=useExperienceReplay,\n",
        "    num_channels=img_channels, img_rows=img_rows\n",
        "  )\n",
        "\n",
        "testGen = csv_image_generator(data_path+'testData.csv', BS, #lb,\n",
        "    mode=\"train\", aug=None,\n",
        "    use_4_frames=use_4_frames, useExperienceReplay=useExperienceReplay,\n",
        "    num_channels=img_channels, img_rows=img_rows\n",
        "  )\n",
        "\n",
        "# initialize our Keras model and compile it\n",
        "if usingSimpleCNN:\n",
        "    model = buildSimpleCNN()\n",
        "elif usingSimpleCoordConv:\n",
        "    model = create_COORDCONV_Simple_CNN()    \n",
        "elif usingMobileNetV2Localizer:\n",
        "    model = create_MobileNetV2_model()\n",
        "\n",
        "# train the network\n",
        "print(\"[INFO] training w/ generator...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=math.ceil(NUM_TRAIN_IMAGES / BS),\n",
        "\tvalidation_data=testGen,\n",
        "\tvalidation_steps=math.ceil(NUM_TEST_IMAGES / BS),\n",
        "\tepochs=NUM_EPOCHS,\n",
        "  callbacks=[history]\n",
        ")\n",
        "\n",
        "model.save(data_path+'model_'+str(NUM_TRAIN_IMAGES)+'_train_images_'+str(NUM_TEST_IMAGES)+'_val_images_'+str(NUM_EPOCHS)+'_epochs.h5')\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = int(NUM_EPOCHS*math.ceil(NUM_TRAIN_IMAGES / BS))\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), history.losses, label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), history.val_losses, label=\"val_loss\")\n",
        "# plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "# plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Loss on Dataset\")\n",
        "plt.xlabel(\"Iteration #\")\n",
        "plt.ylabel(\"MSE Loss\")#/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(data_path+'Learning_Curve_'+str(NUM_TRAIN_IMAGES)+'_train_images_'+str(NUM_TEST_IMAGES)+'_val_images_'+str(NUM_EPOCHS)+'_epochs.png')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "shuffled data\n",
            "num train images:  80000\n",
            "num test images:  20000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "9412608/9406464 [==============================] - 2s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "[INFO] training w/ generator...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/1\n",
            "2499/2500 [============================>.] - ETA: 1s - loss: 880.4428ERROR: completely black image\n",
            "ERROR: completely black image\n",
            "2500/2500 [==============================] - 5727s 2s/step - loss: 880.3401 - val_loss: 1129.4056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-06f6134071c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ggplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;31m# plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     return gca().plot(\n\u001b[1;32m   2810\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2811\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2500,) and (0,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL3LvKT-yLPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print((history.losses).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83oI831jr9i1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# re-initialize our testing data generator, this time for evaluating\n",
        "testGen = csv_image_generator(data_path+'testData.csv', BS, #lb,\n",
        "    mode=\"eval\", aug=None,\n",
        "    use_4_frames=use_4_frames, useExperienceReplay=useExperienceReplay,\n",
        "    num_channels=img_channels, img_rows=img_rows\n",
        "  )\n",
        "\n",
        "# make predictions on the testing images, finding the index of the\n",
        "# label with the corresponding largest predicted probability\n",
        "predIdxs = model.predict_generator(testGen,\n",
        "\tsteps=(NUM_TEST_IMAGES // BS) + 1)\n",
        "# predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(\"[INFO] evaluating network...\")\n",
        "# print(classification_report(testLabels.argmax(axis=1), predIdxs,\n",
        "# \ttarget_names=lb.classes_))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = int(NUM_EPOCHS*math.ceil(NUM_TRAIN_IMAGES / BS))\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), history.losses, label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), history.val_losses, label=\"val_loss\")\n",
        "# plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "# plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Loss on Dataset\")\n",
        "plt.xlabel(\"Iteration #\")\n",
        "plt.ylabel(\"MSE Loss\")#/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(data_path+'Learning_Curve_'+str(NUM_TRAIN_IMAGES)+'_train_images_'+str(NUM_TEST_IMAGES)+'_val_images_'+str(NUM_EPOCHS)+'_epochs.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqBwMITmkZ28",
        "colab_type": "code",
        "outputId": "445ec1af-1e40-4023-b70f-7fe4daa3a4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!ls '/content/gdrive/Shared drives/COMPSCI 760/data/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Copy of FlappyBirdData.zip'   data.txt\t\t'The explaination of data.gdoc'\n",
            " data_new_1st_million.txt      testData.csv\t trainData.csv\n",
            " data_new.txt\t\t       testData.gsheet\t trainData.gsheet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm1ppfVpLEcA",
        "colab_type": "code",
        "outputId": "f791a9ba-ec5c-4643-9d01-bf03399ee731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras import backend\n",
        "print(backend.image_data_format())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "channels_last\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}