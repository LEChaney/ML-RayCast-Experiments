{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Image_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:tensorflow113]",
      "language": "python",
      "name": "conda-env-tensorflow113-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEChaney/ML-RayCast-Experiments/blob/master/supervised_learning_4_localization_simpleCNN_can_train_single_or_stacked_frame_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jw1arH2vxVXK",
        "outputId": "26d237a4-5910-4ab2-82d2-31038148591c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "!git clone https://github.com/LEChaney/ML-RayCast-Experiments\n",
        "%cd ML-RayCast-Experiments\n",
        "%pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML-RayCast-Experiments'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (138/138), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 344 (delta 69), reused 23 (delta 7), pack-reused 206\u001b[K\n",
            "Receiving objects: 100% (344/344), 46.02 MiB | 21.13 MiB/s, done.\n",
            "Resolving deltas: 100% (177/177), done.\n",
            "/content/ML-RayCast-Experiments\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ML-RayCast-Experiments'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nR2rN0ieyYQ5",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "def rotate(image_path):\n",
        "    \"\"\"\n",
        "    Rotate the given photo the amount of given degreesk, show it and save it\n",
        "    @param image_path: The path to the image to edit\n",
        "    @param degrees_to_rotate: The number of degrees to rotate the image\n",
        "    @param saved_location: Path to save the cropped image\n",
        "    \"\"\"\n",
        "    degrees_to_rotate = 180\n",
        "    image_obj = Image.open(image_path)\n",
        "    rotated_image = image_obj.rotate(degrees_to_rotate)\n",
        "    rotated_image.save(\"000.png\")\n",
        "    im = cv2.imread(\"000.png\")\n",
        "    #plt.imshow(im)\n",
        "    #plt.show()\n",
        "    return im\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BqsexcF4qXfE",
        "outputId": "0e50a917-3b70-4654-b7bf-74c2bf7d5146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "os.environ['SDL_VIDEODRIVER']='dummy'\n",
        "file_directory = os.getcwd()\n",
        "os.chdir(\"/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master\")\n",
        "print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iY7nyqTkNMef",
        "outputId": "c9e189cc-7ba6-4b14-8dad-f119a2ff0545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import sys\n",
        "#sys.path.pop(1)\n",
        "sys.path.insert(1,\"/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master/game\")\n",
        "print(sys.path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master/game', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F-j-vysiwaMd",
        "outputId": "e0f90479-a050-4562-c3fd-b8e7f778e8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "%pip install pygame"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 7.3MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-1.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GGMYTHT4OLy4",
        "outputId": "8a085213-3fd7-4a5b-dd35-f409ee8ee75f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "sys.path.append(\"game/\")\n",
        "import wrapped_flappy_bird as game\n",
        "import numpy as np\n",
        "import flappy_bird_utils\n",
        "import cv2\n",
        "import sys\n",
        "import random\n",
        "import pygame\n",
        "import pygame.surfarray as surfarray\n",
        "from pygame.locals import *\n",
        "from itertools import cycle\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "#from cStringIO import StringIO\n",
        "import IPython.display\n",
        "\n",
        "import argparse\n",
        "import skimage as skimage\n",
        "from skimage import transform, color, exposure\n",
        "from skimage.transform import rotate\n",
        "from skimage.viewer import ImageViewer\n",
        "import json\n",
        "\n",
        "from collections import deque"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 1.9.6\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/viewer/__init__.py:6: UserWarning: Viewer requires Qt\n",
            "  warn('Viewer requires Qt')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "epVQmcWzpGRU",
        "outputId": "e33240ea-e71a-4f32-fe0f-2d80e3ba3521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "GAME = 'bird' # the name of the game being played for log files\n",
        "CONFIG = 'nothreshold'\n",
        "ACTIONS = 2 # number of valid actions\n",
        "GAMMA = 0.99 # decay rate of past observations\n",
        "OBSERVATION = 2 #3200. # timesteps to observe before training\n",
        "EXPLORE = 3000000. # frames over which to anneal epsilon\n",
        "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
        "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
        "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
        "BATCH = 32 # size of minibatch\n",
        "FRAME_PER_ACTION = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "FPS = 30\n",
        "SCREENWIDTH  = 288\n",
        "SCREENHEIGHT = 512\n",
        "\n",
        "pygame.init()\n",
        "pygame.display.init()\n",
        "pygame.display.set_mode((1, 1))\n",
        "FPSCLOCK = pygame.time.Clock()\n",
        "SCREEN = pygame.Surface((SCREENWIDTH, SCREENHEIGHT)).convert_alpha()\n",
        "pygame.display.set_caption('Flappy Bird')\n",
        "\n",
        "IMAGES, SOUNDS, HITMASKS = flappy_bird_utils.load()\n",
        "PIPEGAPSIZE = 100 # gap between upper and lower part of pipe\n",
        "BASEY = SCREENHEIGHT * 0.79\n",
        "\n",
        "PLAYER_WIDTH = IMAGES['player'][0].get_width()\n",
        "PLAYER_HEIGHT = IMAGES['player'][0].get_height()\n",
        "PIPE_WIDTH = IMAGES['pipe'][0].get_width()\n",
        "PIPE_HEIGHT = IMAGES['pipe'][0].get_height()\n",
        "BACKGROUND_WIDTH = IMAGES['background'].get_width()\n",
        "\n",
        "PLAYER_INDEX_GEN = cycle([0, 1, 2, 1])\n",
        "\n",
        "img_rows , img_cols = 80, 80\n",
        "#Convert image into Black and white\n",
        "img_channels = 4 #We stack 4 frames\n",
        "\n",
        "game_state = game.GameState()\n",
        "do_nothing = np.zeros(ACTIONS)\n",
        "do_nothing[0] = 1\n",
        "game_state.frame_step(do_nothing)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0, 0, 0]]], dtype=uint8), 0.1, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLkjBOh4Y4FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image_from_coords(data_list):\n",
        "  \n",
        "    CaseNo = int(float(data_list[0]))\n",
        "    game_state.playerx = int(float(data_list[1]))# + SCREENWIDTH /2)\n",
        "    game_state.playery = int(float(data_list[2]))# + SCREENWIDTH /2)\n",
        "    game_state.playerIndex = int(float(data_list[3]))        \n",
        "\n",
        "    game_state.upperPipes = []\n",
        "    game_state.lowerPipes = []\n",
        "\n",
        "    for i in range(4,len(data_list),4):\n",
        "\n",
        "        newPipe = game.getRandomPipe()\n",
        "        game_state.upperPipes.append(newPipe[0])\n",
        "        game_state.upperPipes[int((i-4)/4)]['x'] = int(float(data_list[i]))# + SCREENWIDTH /2)\n",
        "        game_state.upperPipes[int((i-4)/4)]['y'] = int(float(data_list[i+1]))# + SCREENWIDTH /2)\n",
        "\n",
        "        game_state.lowerPipes.append(newPipe[1])\n",
        "        game_state.lowerPipes[int((i-4)/4)]['x'] = int(float(data_list[i+2]))# + SCREENWIDTH /2)\n",
        "#         print(data_list)\n",
        "#         print(len(data_list))\n",
        "#         print(i+3)\n",
        "        game_state.lowerPipes[int((i-4)/4)]['y'] = int(float(data_list[i+3]))# + SCREENWIDTH /2)\n",
        "\n",
        "    # draw sprites\n",
        "    SCREEN.blit(IMAGES['background'], (0,0))\n",
        "\n",
        "    for uPipe, lPipe in zip(game_state.upperPipes, game_state.lowerPipes):\n",
        "        SCREEN.blit(IMAGES['pipe'][0], (uPipe['x'], uPipe['y']))\n",
        "        SCREEN.blit(IMAGES['pipe'][1], (lPipe['x'], lPipe['y']))\n",
        "\n",
        "    SCREEN.blit(IMAGES['base'], (game_state.basex, BASEY))\n",
        "    # print score so player overlaps the score\n",
        "    # showScore(self.score)\n",
        "    SCREEN.blit(IMAGES['player'][game_state.playerIndex],\n",
        "                (game_state.playerx, game_state.playery))\n",
        "\n",
        "    image_data = pygame.surfarray.array3d(SCREEN)\n",
        "    \n",
        "#     IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "#     plt.show()\n",
        "    \n",
        "    image_data = skimage.color.rgb2gray(image_data)\n",
        "    image_data = skimage.transform.resize(image_data,(80,80))\n",
        "    image_data = skimage.exposure.rescale_intensity(image_data, out_range=(0,255))\n",
        "\n",
        "    image_data = image_data / 255.0\n",
        "\n",
        "    image_data = image_data.reshape(1, image_data.shape[0], image_data.shape[1], 1) #1x80x80x1\n",
        "\n",
        "    label = np.array([game_state.playerx, game_state.playery])\n",
        "    \n",
        "#     #print(type(image_data))\n",
        "#     print(\"image_data\" ,image_data)\n",
        "#     print(\"image_data.shape: \", image_data.shape)\n",
        "#     IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "#     #plt.show()\n",
        "\n",
        "    return image_data, label\n",
        "\n",
        "def gen_batch_stacked_frames(file, state, stacked_state_label, bs, D, mode):\n",
        "    \n",
        "    images=[]\n",
        "    labels=[]\n",
        "\n",
        "    while len(images) < bs:  \n",
        "        \n",
        "        current = file.readline().rstrip()\n",
        "\n",
        "        #if reach end of the file start again\n",
        "        if current == \"\":\n",
        "            \n",
        "            file.seek(0)\n",
        "\n",
        "            current = file.readline().rstrip()\n",
        "            \n",
        "            if mode == \"eval\":\n",
        "                break\n",
        "            \n",
        "            data_list = current.split(',')\n",
        "            data_list = [x for x in data_list if str(x) != 'nan']\n",
        "  \n",
        "            image_data, state_label = get_image_from_coords(data_list)\n",
        "            image_data = image_data.reshape(80, 80)\n",
        "            state = np.stack((image_data, image_data, image_data, image_data), axis=2)\n",
        "            state = state.reshape(1, state.shape[0], state.shape[1], state.shape[2])  #1*80*80*4\n",
        "#             state_label = np.array(state_label)\n",
        "            stacked_state_label = np.concatenate((state_label, state_label, state_label, state_label), axis=0).flatten()\n",
        "#             print(stacked_state_label)\n",
        "#             stacked_state_label = stacked_state_label.flatten()\n",
        "#             print('stacked_state_label: ', stacked_state_label) \n",
        "            #state = state.reshape(state.shape[0],)\n",
        "            \n",
        "            # store the transition in D\n",
        "            D.append((state, stacked_state_label))   \n",
        "            \n",
        "#             if current[0] == \"-\":\n",
        "#                 continue\n",
        "        else:   \n",
        "            \n",
        "            data_list = current.split(',')\n",
        "#             if len(images) == 10:\n",
        "#                 print(data_list)\n",
        "            \n",
        "            data_list = [x for x in data_list if str(x) != 'nan']\n",
        "            \n",
        "#             print('no. in batch: ', len(images))\n",
        "            \n",
        "#             if len(images) == 10:\n",
        "#                 print(data_list)\n",
        "#                   print(len(data_list))\n",
        "            \n",
        "            image_data, state_label = get_image_from_coords(data_list)\n",
        "\n",
        "    #             state.append(image_data)\n",
        "    #             state_labels.append(state_label)\n",
        "#             print(state.shape)\n",
        "#             print(image_data.shape)\n",
        "            state = np.append(image_data, state[:, :, :, :3], axis=3)\n",
        "#             stacked_state_label = np.append(stacked_state_label, stacked_state_label[:6]).flatten()\n",
        "#             print(state_label.shape)\n",
        "#             print(stacked_state_label.shape)\n",
        "            stacked_state_label = np.concatenate((state_label, stacked_state_label[:6]), axis=0).flatten()\n",
        "#             print(stacked_state_label)\n",
        "#             stacked_state_label = stacked_state_label.flatten()\n",
        "#             print('stacked_state_label.shape: ', stacked_state_label.shape) \n",
        "            #state = np.array(state)\n",
        "            #state = state.reshape(state.shape[0],)\n",
        "        \n",
        "            # store the transition in D\n",
        "            D.append((state, stacked_state_label))\n",
        "        \n",
        "        if len(D) > REPLAY_MEMORY:\n",
        "            D.popleft()\n",
        "#         print(len(D))\n",
        "\n",
        "        # training with experience replay\n",
        "        miniBatch = random.sample(D,1)\n",
        "        gen_state, gen_label = zip(*miniBatch)\n",
        "#         print('gen_state: ', gen_state[0])\n",
        "#         print('gen_label: ', gen_label[0])\n",
        "        images.append(gen_state[0])\n",
        "#         print(gen_label[0])\n",
        "        labels.append(gen_label[0])\n",
        "#         print('len(labels): ', len(labels))\n",
        "    \n",
        "    images = np.array(images)\n",
        "#     print(images.shape)\n",
        "    images = images.reshape(bs, 80, 80, 4)\n",
        "#     print(images.shape)\n",
        "#     print('labels: ', labels)\n",
        "    labels = np.array(labels)\n",
        "#     print('labels: ', labels)\n",
        "#     print('labels.shape: ', labels.shape)\n",
        "    labels = labels.reshape(bs, 8)\n",
        "#     print('labels.shape: ', labels.shape)\n",
        "    # if the data augmentation object is not None, apply it\n",
        "    if aug is not None:\n",
        "      (images, labels) = next(aug.flow(images, labels, batch_size=bs))\n",
        "    \n",
        "    return images, labels, state, stacked_state_label\n",
        "  \n",
        "def gen_batch_single_frame(file, bs, D, mode):\n",
        "    \n",
        "    images=[]\n",
        "    labels=[]\n",
        "\n",
        "    while len(images) < bs:  \n",
        "        \n",
        "        current = file.readline().rstrip()\n",
        "\n",
        "        #if reach end of the file start again\n",
        "        if current == \"\":\n",
        "            \n",
        "            file.seek(0)\n",
        "            current = file.readline().rstrip()\n",
        "            \n",
        "            if mode == \"eval\":\n",
        "                break\n",
        "            \n",
        "        data_list = current.split(',')\n",
        "#         if len(images) == 10:\n",
        "#             print(data_list)\n",
        "\n",
        "        data_list = [x for x in data_list if str(x) != 'nan']\n",
        "\n",
        "#         print('no. in batch: ', len(images))\n",
        "\n",
        "#         if len(images) == 10:\n",
        "#             print(data_list)\n",
        "#               print(len(data_list))\n",
        "\n",
        "        image_data, state_label = get_image_from_coords(data_list)\n",
        "        \n",
        "        # store the transition in D\n",
        "        if D is not None:\n",
        "            D.append((state, state_label))\n",
        "            if len(D) > REPLAY_MEMORY:\n",
        "                D.popleft()\n",
        "#             print(len(D))\n",
        "        \n",
        "            # training with experience replay\n",
        "            miniBatch = random.sample(D,1)\n",
        "            gen_state, gen_label = zip(*miniBatch)\n",
        "            images.append(gen_state)\n",
        "            labels.append(gen_label)\n",
        "        else:\n",
        "            images.append(image_data)\n",
        "            labels.append(state_label)\n",
        "    \n",
        "    images = np.array(images)\n",
        "#     print(images.shape)\n",
        "    images = images.reshape(bs, 80, 80, 1)\n",
        "#     print(images.shape)\n",
        "    labels = np.array(labels)\n",
        "#     print(labels.shape)\n",
        "    labels = labels.reshape(bs, 2)\n",
        "#     print(labels.shape)\n",
        "    # if the data augmentation object is not None, apply it\n",
        "    if aug is not None:\n",
        "      (images, labels) = next(aug.flow(images, labels, batch_size=bs))\n",
        "    \n",
        "    return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oFd4h0qxcNXw",
        "colab": {}
      },
      "source": [
        "\n",
        "'''import numpy as np\n",
        "import sys\n",
        "import random\n",
        "import pygame\n",
        "import flappy_bird_utils\n",
        "import pygame.surfarray as surfarray\n",
        "from pygame.locals import *\n",
        "from itertools import cycle'''\n",
        "\n",
        "def csv_image_generator(filepath, bs, mode=\"train\", aug=None, use_4_frames=False, useExperienceReplay=False):\n",
        "\n",
        "    file = open(filepath,\"r\")\n",
        "    \n",
        "    maxCount = 100\n",
        "    count = maxCount\n",
        "       \n",
        "    # initialize state\n",
        "    current = file.readline().rstrip()\n",
        "  \n",
        "    data_list = current.split(',')\n",
        "\n",
        "#     print(data_list)\n",
        "    data_list = [x for x in data_list if str(x) != 'nan']          \n",
        "#     print(data_list)\n",
        "\n",
        "    image_data, state_label = get_image_from_coords(data_list)\n",
        "        \n",
        "#     print(type(image_data))\n",
        "#     print(\"image_data\" ,image_data)\n",
        "#     print(\"image_data.shape: \", image_data.shape)\n",
        "#     IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "#     plt.show()\n",
        "  \n",
        "    image_data = image_data.reshape(80, 80)\n",
        "#     print(image_data.shape)\n",
        "  \n",
        "    if use_4_frames:\n",
        "\n",
        "        state = np.stack((image_data, image_data, image_data, image_data), axis=2)\n",
        "  #         print(state.shape)\n",
        "        state = state.reshape(1, state.shape[0], state.shape[1], state.shape[2])  #1*80*80*4\n",
        "        stacked_state_label = np.concatenate((state_label, state_label, state_label, state_label), axis=0).flatten()\n",
        "#         print('stacked_state_label first: ', stacked_state_label)\n",
        "#         stacked_state_label = stacked_state_label.flatten()\n",
        "        print('stacked_state_label first flattened: ', stacked_state_label)    \n",
        "\n",
        "        # store the previous observations in replay memory\n",
        "        D = deque()\n",
        "        D.append((state, stacked_state_label)) \n",
        "\n",
        "        while True:\n",
        "\n",
        "  #             count -= 1\n",
        "  #             if count > 1:\n",
        "  #                 continue\n",
        "  #             if count == 0:\n",
        "  #                 break;\n",
        "  #             print('count: ', count)\n",
        "\n",
        "            images, labels, state, stacked_state_label = gen_batch_stacked_frames(file, state, stacked_state_label, bs, D, mode)\n",
        "\n",
        "            # yield the batch to the calling function\n",
        "  #             print(images.shape)\n",
        "  #             print(labels.shape)\n",
        "\n",
        "            yield (images, labels)    \n",
        "\n",
        "    elif useExperienceReplay:    \n",
        "\n",
        "        # store the previous observations in replay memory\n",
        "        D = deque()\n",
        "        D.append((image_data, state_label)) \n",
        "\n",
        "        while True:\n",
        "          \n",
        "#             count -= 1\n",
        "#             if count > 1:\n",
        "#                 continue\n",
        "#             if count == 0:\n",
        "#                 break;\n",
        "#             print('count: ', count)\n",
        "            \n",
        "            images, labels = gen_batch_single_frame(file, bs, D, mode)\n",
        "        \n",
        "            # yield the batch to the calling function\n",
        "#             print(images.shape)\n",
        "#             print(labels.shape)\n",
        "            \n",
        "            yield (images, labels)   \n",
        "    \n",
        "    else:\n",
        "      \n",
        "        while True:\n",
        "          \n",
        "#             count -= 1\n",
        "#             if count > 1:\n",
        "#                 continue\n",
        "#             if count == 0:\n",
        "#                 break;\n",
        "#             print('count: ', count)\n",
        "            \n",
        "            images, labels = gen_batch_single_frame(file, bs, D=None, mode=mode)\n",
        "        \n",
        "            # yield the batch to the calling function\n",
        "#             print(images.shape)\n",
        "#             print(labels.shape)\n",
        "            \n",
        "            yield (images, labels)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RoY9XL6ERYaG",
        "outputId": "f90d7193-c87d-4dd7-bf21-b39ee1a6f597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# file= \"data.csv\" #file path or a file in the current folder\n",
        "# csv_image_generator(file, 8, mode=\"train\", aug=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object csv_image_generator at 0x7f6805691990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPzIfBewKg4S",
        "colab_type": "code",
        "outputId": "cb0b565f-5be1-4b87-a2af-186a688542b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "!pip install Keras-CoordConv\n",
        "# !pip install pyimagesearch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Keras-CoordConv\n",
            "  Downloading https://files.pythonhosted.org/packages/d2/aa/4bbce2d9645afa6523df8d8a53832d8999367e8f89297a43382146814f15/Keras_CoordConv-0.6.tar.gz\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from Keras-CoordConv) (2.2.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.16.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.3.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->Keras-CoordConv) (1.0.8)\n",
            "Building wheels for collected packages: Keras-CoordConv\n",
            "  Building wheel for Keras-CoordConv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Keras-CoordConv: filename=Keras_CoordConv-0.6-cp36-none-any.whl size=7578 sha256=70f752f68a8927397c93105e2fc9b23811f2fa37becbc2b8cad0c010d2dd4195\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/32/98/8eeb612bb1bee30a9ee99ff406da961bcfef37fc7cf14f4120\n",
            "Successfully built Keras-CoordConv\n",
            "Installing collected packages: Keras-CoordConv\n",
            "Successfully installed Keras-CoordConv-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0keTKP-0OZUO",
        "colab_type": "code",
        "outputId": "c8669e5f-1050-4c62-adac-e8ad04412b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!rm trainData.csv\n",
        "!rm testData.csv\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "animation1.gif\tdata.txt     model.h5\t\t    qlearn.py\n",
            "assets\t\tgame\t     model.json\t\t    qlearn_ray.py\n",
            "data.csv\t__init__.py  qlearn_loc_and_ray.py  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bd04oRFiRKJc",
        "outputId": "0e096e56-c542-4cc6-c3f2-dc001626b0f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "# USAGE\n",
        "# python train.py\n",
        "\n",
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "import sys\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.initializers import normal, identity\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from tensorflow.keras.layers import Conv2D, Reshape\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.backend import epsilon\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from Keras_CoordConv.coord import CoordinateChannel2D\n",
        "# from coord import CoordinateChannel2D\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "img_rows , img_cols = 80, 80\n",
        "#Convert image into Black and white\n",
        "\n",
        "use_single_frame = True\n",
        "use_4_frames = False #If We stack 4 frames for model input\n",
        "\n",
        "if use_single_frame == True:\n",
        "    img_channels = 1 #single frame for model input\n",
        "    out_shape = 2 #2 ouptut neurons for single x, y player coordinate for output\n",
        "else:\n",
        "    img_channels = 4 #stack 4 frames for model input\n",
        "    out_shape = 8 #8 output neurons for 4 pairs of x, y player coordinate for output\n",
        "    \n",
        "usingSimpleCNN = 1\n",
        "usingSimpleCoordConv = 0\n",
        "usingMobileNetV2Localizer = 0\n",
        "\n",
        "useExperienceReplay = False\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "def buildSimpleCNN():\n",
        "    print(\"Now we build the model\")\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(32, 8, 8, subsample=(4,4), border_mode='same', input_shape=(img_cols,img_rows,img_channels)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(64, 4, 4, subsample=(2,2), border_mode='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(64, 3, 3, subsample=(1,1), border_mode='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(out_shape))\n",
        "   \n",
        "    adam = Adam(lr=1e-6)\n",
        "    model.compile(loss='mse',optimizer=adam)\n",
        "    print(\"We finish building the model\")\n",
        "    return model\n",
        "\n",
        "def create_COORDCONV_Simple_CNN():\n",
        "    print(\"Now we build the model\")\n",
        "    ip = Input(shape=(img_rows,img_cols,img_channels))\n",
        "    x = CoordinateChannel2D()(ip)\n",
        "    x = Convolution2D(32, 8, 8, subsample=(4,4), border_mode='same')\n",
        "    x = Activation('relu')\n",
        "    x = CoordinateChannel2D()(x)\n",
        "    x = Convolution2D(64, 4, 4, subsample=(2,2), border_mode='same')\n",
        "    x = Activation('relu')\n",
        "    x = CoordinateChannel2D()(x)\n",
        "    x = Convolution2D(64, 3, 3, subsample=(1,1), border_mode='same')\n",
        "    x = Activation('relu')\n",
        "    x = Flatten()\n",
        "    x = Dense(512)\n",
        "    x = Activation('relu')\n",
        "    x = Dense(out_shape)\n",
        "    model = keras.Model(inputs=ip, outputs=x)\n",
        "    adam = Adam(lr=1e-6)\n",
        "    model.compile(loss='mse',optimizer=adam)\n",
        "    return model\n",
        "\n",
        "\"\"\"\n",
        "# prior to first conv\n",
        "ip = Input(shape=(64, 64, 2))\n",
        "x = CoordinateChannel2D()(ip)\n",
        "x = Conv2D(...)(x)  # This defines the `CoordConv` from the paper.\n",
        "...\n",
        "x = CoordinateChannel2D(use_radius=True)(x)\n",
        "x = Conv2D(...)(x)  # This adds the 3rd channel for the radius.\n",
        "\"\"\"\n",
        "def create_MobileNetV2_model(trainable=False):\n",
        "    model = MobileNetV2(input_shape=(img_channels,img_rows,img_cols), include_top=False)\n",
        "\n",
        "    # to freeze layers\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    x = model.layers[-1].output\n",
        "    x = Conv2D(4, kernel_size=3, name=\"coords\")(x)\n",
        "    x = Reshape((out_shape,))(x)\n",
        "\n",
        "    model = Model(inputs=model.input, outputs=x)\n",
        "    adam = Adam(lr=1e-6)\n",
        "    model.compile(loss='mse', optimizer=adam)\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_train_test_split():\n",
        "    data = np.genfromtxt('data.csv', delimiter=',')\n",
        "    if use_single_frame and not useExperienceReplay:\n",
        "        data = np.take(data,np.random.rand(data.shape[0]).argsort(),axis=0,out=data)\n",
        "        print('shuffled data')\n",
        "#         data = np.random.shuffle(data)\n",
        "    traintestsplit = np.split(data, [int(4*data.shape[0]/5)])\n",
        "    train = traintestsplit[0]\n",
        "    test = traintestsplit[1]\n",
        "#     print(train[108])\n",
        "    return train, test\n",
        "\n",
        "# initialize the paths to our training and testing CSV files\n",
        "#TRAIN_CSV = \"flowers17_training.csv\"\n",
        "#TEST_CSV = \"flowers17_testing.csv\"\n",
        "\n",
        "TRAIN, TEST = get_train_test_split()\n",
        "\n",
        "# initialize the number of epochs to train for and batch size\n",
        "NUM_EPOCHS = 75\n",
        "BS = 32\n",
        "\n",
        "# initialize the total number of training and testing image\n",
        "NUM_TRAIN_IMAGES = 0\n",
        "NUM_TEST_IMAGES = 0\n",
        "\n",
        "# open the training CSV file, then initialize the unique set of class\n",
        "# labels in the dataset along with the testing labels\n",
        "#f = open(TRAIN_CSV, \"r\")\n",
        "labels = set()\n",
        "testLabels = []\n",
        "\n",
        "'''\n",
        "# loop over all rows of the CSV file\n",
        "for row in TRAIN:\n",
        "\t# extract the class label, update the labels list, and increment\n",
        "\t# the total number of training images\n",
        "\tlabel = line.strip().split(\",\")[0]\n",
        "\tlabels.add(label)\n",
        "\tNUM_TRAIN_IMAGES += 1\n",
        "\n",
        "# close the training CSV file and open the testing CSV file\n",
        "f.close()\n",
        "f = open(TEST_CSV, \"r\")\n",
        "\n",
        "# loop over the lines in the testing file\n",
        "for row in TEST:\n",
        "\t# extract the class label, update the test labels list, and\n",
        "\t# increment the total number of testing images\n",
        "\tlabel = line.strip().split(\",\")[0]\n",
        "\ttestLabels.append(label)\n",
        "\tNUM_TEST_IMAGES += 1\n",
        "\n",
        "# close the testing CSV file\n",
        "f.close()\n",
        "'''\n",
        "\n",
        "trainLabels = TRAIN[:,1:3]\n",
        "trainData = TRAIN[:,:]\n",
        "np.savetxt('trainData.csv', trainData, delimiter=',')\n",
        "NUM_TRAIN_IMAGES = trainData.shape[0]\n",
        "\n",
        "print('num train images: ', NUM_TRAIN_IMAGES)\n",
        "\n",
        "# file = open('trainData.csv', \"r\")\n",
        "\n",
        "# for i in range(101):\n",
        "#     current = file.readline().rstrip()\n",
        "# data_list = current.split(',')\n",
        "# print(data_list)\n",
        "# data_list = [x for x in data_list if str(x) != 'nan']          \n",
        "# print(data_list)\n",
        "# image_data, state_label = get_image_from_coords(data_list)\n",
        "# file.close()\n",
        "# # print(type(image_data))\n",
        "# # print(\"image_data\" ,image_data)\n",
        "\n",
        "# image_data = image_data.reshape(80,80)\n",
        "# print(\"image_data.shape: \", image_data.shape)\n",
        "\n",
        "# IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "testLabels = TEST[:,1:3]\n",
        "testData = TEST[:,:]\n",
        "np.savetxt('testData.csv', testData, delimiter=',')\n",
        "NUM_TEST_IMAGES = testData.shape[0]\n",
        "\n",
        "print('num test images: ', NUM_TEST_IMAGES)\n",
        "\n",
        "# create the label binarizer for one-hot encoding labels, then encode\n",
        "# the testing labels\n",
        "# lb = LabelBinarizer()\n",
        "# lb.fit(list(trainLabels))\n",
        "# testLabels = lb.transform(testLabels)\n",
        "\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2, fill_mode=\"nearest\")\n",
        "\n",
        "# initialize both the training and testing image generators\n",
        "trainGen = csv_image_generator('trainData.csv', BS, #lb,\n",
        "    mode=\"train\", aug=aug,\n",
        "    use_4_frames=use_4_frames, useExperienceReplay=useExperienceReplay\n",
        "  )\n",
        "\n",
        "testGen = csv_image_generator('testData.csv', BS, #lb,\n",
        "    mode=\"train\", aug=None,\n",
        "    use_4_frames=use_4_frames, useExperienceReplay=useExperienceReplay\n",
        "  )\n",
        "\n",
        "# initialize our Keras model and compile it\n",
        "if usingSimpleCNN:\n",
        "    model = buildSimpleCNN()\n",
        "elif usingSimpleCoordConv:\n",
        "    model = create_COORDCONV_Simple_CNN()    \n",
        "elif usingMobileNetV2Localizer:\n",
        "    model = create_MobileNetV2_model()\n",
        "\n",
        "# train the network\n",
        "print(\"[INFO] training w/ generator...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=math.ceil(NUM_TRAIN_IMAGES / BS),\n",
        "\tvalidation_data=testGen,\n",
        "\tvalidation_steps=math.ceil(NUM_TEST_IMAGES / BS),\n",
        "\tepochs=NUM_EPOCHS)\n",
        "\n",
        "# re-initialize our testing data generator, this time for evaluating\n",
        "testGen = csv_image_generator(TEST_CSV, BS, #lb,\n",
        "    mode=\"eval\", aug=None,\n",
        "    use_4_frames=use_4_frames, useExperienceReplay=useExperienceReplay\n",
        "  )\n",
        "\n",
        "# make predictions on the testing images, finding the index of the\n",
        "# label with the corresponding largest predicted probability\n",
        "predIdxs = model.predict_generator(testGen,\n",
        "\tsteps=(NUM_TEST_IMAGES // BS) + 1)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(\"[INFO] evaluating network...\")\n",
        "print(classification_report(testLabels.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=lb.classes_))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = NUM_EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"plot.png\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "shuffled data\n",
            "num train images:  80008\n",
            "num test images:  20003\n",
            "Now we build the model\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (8, 8), input_shape=(80, 80, 1..., strides=(4, 4), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "We finish building the model\n",
            "[INFO] training w/ generator...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/75\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1095/2501 [============>.................] - ETA: 21:43 - loss: 16585.6684"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}