{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Image_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:tensorflow113]",
      "language": "python",
      "name": "conda-env-tensorflow113-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEChaney/ML-RayCast-Experiments/blob/master/supervised_learning_4_localization_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jw1arH2vxVXK",
        "outputId": "963d5729-88f6-4d76-a48f-fee67850aa1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!git clone https://github.com/LEChaney/ML-RayCast-Experiments\n",
        "%cd ML-RayCast-Experiments\n",
        "%pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML-RayCast-Experiments'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 329 (delta 59), reused 24 (delta 7), pack-reused 206\u001b[K\n",
            "Receiving objects: 100% (329/329), 46.01 MiB | 11.49 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n",
            "/content/ML-RayCast-Experiments\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ML-RayCast-Experiments'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nR2rN0ieyYQ5",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "def rotate(image_path):\n",
        "    \"\"\"\n",
        "    Rotate the given photo the amount of given degreesk, show it and save it\n",
        "    @param image_path: The path to the image to edit\n",
        "    @param degrees_to_rotate: The number of degrees to rotate the image\n",
        "    @param saved_location: Path to save the cropped image\n",
        "    \"\"\"\n",
        "    degrees_to_rotate = 180\n",
        "    image_obj = Image.open(image_path)\n",
        "    rotated_image = image_obj.rotate(degrees_to_rotate)\n",
        "    rotated_image.save(\"000.png\")\n",
        "    im = cv2.imread(\"000.png\")\n",
        "    #plt.imshow(im)\n",
        "    #plt.show()\n",
        "    return im\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BqsexcF4qXfE",
        "outputId": "1c638c7b-e290-4c58-9bc4-70d8c9e1d466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.environ['SDL_VIDEODRIVER']='dummy'\n",
        "file_directory = os.getcwd()\n",
        "os.chdir(\"/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master\")\n",
        "print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iY7nyqTkNMef",
        "outputId": "41ba2e26-14e3-443f-a103-3256779ae30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import sys\n",
        "#sys.path.pop(1)\n",
        "sys.path.insert(1,\"/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master/game\")\n",
        "print(sys.path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/content/ML-RayCast-Experiments/Keras-FlappyBird-master/Keras-FlappyBird-master/game', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F-j-vysiwaMd",
        "outputId": "7c08ab03-a59e-489a-e84f-9311137b6c8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%pip install pygame"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-1.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GGMYTHT4OLy4",
        "outputId": "416aca6c-a37b-4822-a298-5e305b20c8ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import wrapped_flappy_bird as game\n",
        "import numpy as np\n",
        "import flappy_bird_utils\n",
        "import cv2\n",
        "import sys\n",
        "import random\n",
        "import pygame\n",
        "import pygame.surfarray as surfarray\n",
        "from pygame.locals import *\n",
        "from itertools import cycle\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "#from cStringIO import StringIO\n",
        "import IPython.display\n",
        "\n",
        "import skimage as skimage\n",
        "from skimage import transform, color, exposure\n",
        "from skimage.transform import rotate\n",
        "from skimage.viewer import ImageViewer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 1.9.6\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/viewer/__init__.py:6: UserWarning: Viewer requires Qt\n",
            "  warn('Viewer requires Qt')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "epVQmcWzpGRU",
        "outputId": "b9adc57c-856f-47d0-f7c5-0844fd885264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "GAME = 'bird' # the name of the game being played for log files\n",
        "CONFIG = 'nothreshold'\n",
        "ACTIONS = 2 # number of valid actions\n",
        "GAMMA = 0.99 # decay rate of past observations\n",
        "OBSERVATION = 3200. # timesteps to observe before training\n",
        "EXPLORE = 3000000. # frames over which to anneal epsilon\n",
        "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
        "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
        "REPLAY_MEMORY = 50000 # number of previous transitions to remember\n",
        "BATCH = 32 # size of minibatch\n",
        "FRAME_PER_ACTION = 1\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "FPS = 30\n",
        "SCREENWIDTH  = 288\n",
        "SCREENHEIGHT = 512\n",
        "\n",
        "pygame.init()\n",
        "pygame.display.init()\n",
        "pygame.display.set_mode((1, 1))\n",
        "FPSCLOCK = pygame.time.Clock()\n",
        "SCREEN = pygame.Surface((SCREENWIDTH, SCREENHEIGHT)).convert_alpha()\n",
        "pygame.display.set_caption('Flappy Bird')\n",
        "\n",
        "IMAGES, SOUNDS, HITMASKS = flappy_bird_utils.load()\n",
        "PIPEGAPSIZE = 100 # gap between upper and lower part of pipe\n",
        "BASEY = SCREENHEIGHT * 0.79\n",
        "\n",
        "PLAYER_WIDTH = IMAGES['player'][0].get_width()\n",
        "PLAYER_HEIGHT = IMAGES['player'][0].get_height()\n",
        "PIPE_WIDTH = IMAGES['pipe'][0].get_width()\n",
        "PIPE_HEIGHT = IMAGES['pipe'][0].get_height()\n",
        "BACKGROUND_WIDTH = IMAGES['background'].get_width()\n",
        "\n",
        "PLAYER_INDEX_GEN = cycle([0, 1, 2, 1])\n",
        "\n",
        "img_rows , img_cols = 80, 80\n",
        "#Convert image into Black and white\n",
        "img_channels = 4 #We stack 4 frames\n",
        "\n",
        "game_state = game.GameState()\n",
        "do_nothing = np.zeros(ACTIONS)\n",
        "do_nothing[0] = 1\n",
        "game_state.frame_step(do_nothing)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0, 0, 0]]], dtype=uint8), 0.1, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLkjBOh4Y4FG",
        "colab_type": "code",
        "outputId": "48f9ecfb-d770-40c7-e448-63a522915780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "def get_image_from_coords(data_list):\n",
        "  \n",
        "    CaseNo = int(float(data_list[0]))\n",
        "    game_state.playerx = int(float(data_list[1]))# + SCREENWIDTH /2)\n",
        "    game_state.playery = int(float(data_list[2]))# + SCREENWIDTH /2)\n",
        "    game_state.playerIndex = int(data_list[3])        \n",
        "\n",
        "    game_state.upperPipes = []\n",
        "    game_state.lowerPipes = []\n",
        "\n",
        "    for i in range(4,len(data_list),4):\n",
        "\n",
        "        newPipe = game.getRandomPipe()\n",
        "        game_state.upperPipes.append(newPipe[0])\n",
        "        game_state.upperPipes[int((i-4)/4)]['x'] = int(float(data_list[i]))# + SCREENWIDTH /2)\n",
        "        game_state.upperPipes[int((i-4)/4)]['y'] = int(float(data_list[i+1]))# + SCREENWIDTH /2)\n",
        "\n",
        "        game_state.lowerPipes.append(newPipe[1])\n",
        "        game_state.lowerPipes[int((i-4)/4)]['x'] = int(float(data_list[i+2]))# + SCREENWIDTH /2)\n",
        "        game_state.lowerPipes[int((i-4)/4)]['y'] = int(float(data_list[i+3]))# + SCREENWIDTH /2)\n",
        "\n",
        "    # draw sprites\n",
        "    SCREEN.blit(IMAGES['background'], (0,0))\n",
        "\n",
        "    for uPipe, lPipe in zip(game_state.upperPipes, game_state.lowerPipes):\n",
        "        SCREEN.blit(IMAGES['pipe'][0], (uPipe['x'], uPipe['y']))\n",
        "        SCREEN.blit(IMAGES['pipe'][1], (lPipe['x'], lPipe['y']))\n",
        "\n",
        "    SCREEN.blit(IMAGES['base'], (game_state.basex, BASEY))\n",
        "    # print score so player overlaps the score\n",
        "    # showScore(self.score)\n",
        "    SCREEN.blit(IMAGES['player'][game_state.playerIndex],\n",
        "                (game_state.playerx, game_state.playery))\n",
        "\n",
        "    image_data = pygame.surfarray.array3d(SCREEN)\n",
        "    #IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "\n",
        "    image_data = skimage.color.rgb2gray(image_data)\n",
        "    image_data = skimage.transform.resize(image_data,(80,80))\n",
        "    image_data = skimage.exposure.rescale_intensity(image_data, out_range=(0,255))\n",
        "\n",
        "    image_data = image_data / 255.0\n",
        "\n",
        "    image_data = image_data.reshape(1, image_data.shape[0], image_data.shape[1], 1) #1x80x80x1\n",
        "\n",
        "    label = [game_state.playerx, game_state.playery]\n",
        "    \n",
        "    return image_data, label\n",
        "\n",
        "def gen_batch(file, bs, D):\n",
        "    \n",
        "    images=[]\n",
        "    labels=[]\n",
        "        \n",
        "    state = []\n",
        "    state_labels = []\n",
        "\n",
        "    while len(images) < bs:  \n",
        "        \n",
        "        current = file.readline()\n",
        "\n",
        "        #if reach end of the file start again\n",
        "        if current == \"\":\n",
        "            \n",
        "            file.seek(0)\n",
        "\n",
        "            current = file.readline()\n",
        "\n",
        "            data_list = current.split(',')\n",
        "            data_list.pop()\n",
        "\n",
        "            image_data, state_label = get_image_from_coords(data_list)\n",
        "            state = np.stack((image_data, image_data, image_data, image_data), axis=2)\n",
        "            state = state.reshape(1, state.shape[0], state.shape[1], state.shape[2])  #1*80*80*4\n",
        "            state_label = np.array(state_label)\n",
        "            state_labels = np.stack((label, label, label, label), axis=2).flatten()\n",
        "\n",
        "        #state = state.reshape(state.shape[0],)\n",
        "                # store the transition in D\n",
        "            D.append((state, state_labels))   \n",
        "            \n",
        "#             if current[0] == \"-\":\n",
        "#                 continue\n",
        "        else:   \n",
        "            \n",
        "            data_list = current.split(',')\n",
        "            data_list.pop()\n",
        "\n",
        "            image_data, state_label = get_image_from_coords(data_list)\n",
        "\n",
        "    #             state.append(image_data)\n",
        "    #             state_labels.append(label)\n",
        "\n",
        "            state = np.append(image_data, state[:, :, :, :3], axis=3)\n",
        "            state_labels = np.append(state_label, state_labels[:6]).flatten()\n",
        "            #state = np.array(state)\n",
        "            #state = state.reshape(state.shape[0],)\n",
        "        \n",
        "        # store the transition in D\n",
        "        D.append((state, state_labels))\n",
        "        if len(D) > REPLAY_MEMORY:\n",
        "            D.popleft()\n",
        "\n",
        "        gen_state, gen_label = random.sample(D,1)\n",
        "        images.append(gen_state)\n",
        "        labels.append(gen_label)\n",
        "            \n",
        "    # if the data augmentation object is not None, apply it\n",
        "    if aug is not None:\n",
        "      (images, labels) = next(aug.flow(np.array(images), labels, batch_size=bs))\n",
        "    \n",
        "        #running = False\n",
        "    #print(type(image_data))\n",
        "    print(\"image_data\" ,image_data)\n",
        "    print(\"image_data.shape: \", image_data.shape)\n",
        "    IPython.display.display(PIL.Image.fromarray(image_data))\n",
        "    #plt.show()\n",
        "    \n",
        "    return images, labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-bbcc12b308f6>\"\u001b[0;36m, line \u001b[0;32m55\u001b[0m\n\u001b[0;31m    count--\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oFd4h0qxcNXw",
        "colab": {}
      },
      "source": [
        "\n",
        "'''import numpy as np\n",
        "import sys\n",
        "import random\n",
        "import pygame\n",
        "import flappy_bird_utils\n",
        "import pygame.surfarray as surfarray\n",
        "from pygame.locals import *\n",
        "from itertools import cycle'''\n",
        "\n",
        "def csv_image_generator(filepath, bs, mode=\"train\", aug=None):\n",
        "\n",
        "    file = open(filepath,\"r\")\n",
        "    \n",
        "    maxCount = 100\n",
        "    count = maxCount\n",
        "    lineNum = 0\n",
        "    \n",
        "    # store the previous observations in replay memory\n",
        "    D = deque()\n",
        "    \n",
        "    # initialize state\n",
        "    current = file.readline()\n",
        "\n",
        "    data_list = current.split(',')\n",
        "    data_list.pop()\n",
        "\n",
        "    image_data, state_label = get_image_from_coords(data_list)\n",
        "    state = np.stack((image_data, image_data, image_data, image_data), axis=2)\n",
        "    state = state.reshape(1, state.shape[0], state.shape[1], state.shape[2])  #1*80*80*4\n",
        "    state_label = np.array(state_label)\n",
        "    state_labels = np.stack((label, label, label, label), axis=2).flatten()\n",
        "    \n",
        "    #state = state.reshape(state.shape[0],)\n",
        "        # store the transition in D\n",
        "    D.append((state, state_labels)) \n",
        "    \n",
        "    while True:\n",
        "        \n",
        "        count -= 1\n",
        "\n",
        "#         if count > 1:\n",
        "#             continue\n",
        "#         if count == 0:\n",
        "#             break;\n",
        "        \n",
        "        images, labels = get_batch(file, bs, D)\n",
        "        \n",
        "        # yield the batch to the calling function\n",
        "        yield (np.array(images), np.array(labels))    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RoY9XL6ERYaG",
        "outputId": "f90d7193-c87d-4dd7-bf21-b39ee1a6f597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "file= \"data.txt\" #file path or a file in the current folder\n",
        "csv_image_generator(file, 8, mode=\"train\", aug=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object csv_image_generator at 0x7f6805691990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bd04oRFiRKJc",
        "outputId": "c35a1520-d415-4f99-e319-702c4e9644e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# USAGE\n",
        "# python train.py\n",
        "\n",
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "import sys\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD, adam\n",
        "from keras.initializers import normal, identity\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from tensorflow.keras.layers import Conv2D, Reshape\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.backend import epsilon\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from pyimagesearch.minivggnet import MiniVGGNet\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from coord import CoordinateChannel2D\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "img_rows , img_cols = 80, 80\n",
        "#Convert image into Black and white\n",
        "img_channels = 4 #We stack 4 frames\n",
        "\n",
        "usingSimpleCNN = 1\n",
        "usingSimpleCoordConv = 0\n",
        "usingMobileNetV2Localizer = 0\n",
        "\n",
        "def buildSimpleCNN():\n",
        "    print(\"Now we build the model\")\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(32, 8, 8, subsample=(4,4), border_mode='same', input_shape=(img_rows,img_cols,img_channels)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(64, 4, 4, subsample=(2,2), border_mode='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Convolution2D(64, 3, 3, subsample=(1,1), border_mode='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(8))\n",
        "   \n",
        "    adam = Adam(lr=1e-6)\n",
        "    model.compile(loss='mse',optimizer=adam)\n",
        "    print(\"We finish building the model\")\n",
        "    return model\n",
        "\n",
        "def create_COORDCONV_Simple_CNN():\n",
        "    print(\"Now we build the model\")\n",
        "    ip = (img_rows,img_cols,img_channels)\n",
        "    x = CoordinateChannel2D()(ip)\n",
        "    x = Convolution2D(32, 8, 8, subsample=(4,4),init=lambda shape, name: normal(shape, scale=0.01, name=name), border_mode='same')\n",
        "    x = (Activation('relu')\n",
        "    x = CoordinateChannel2D()(x)\n",
        "    x = Convolution2D(64, 4, 4, subsample=(2,2),init=lambda shape, name: normal(shape, scale=0.01, name=name), border_mode='same')\n",
        "    x = Activation('relu')\n",
        "    x = CoordinateChannel2D()(x)\n",
        "    x = Convolution2D(64, 3, 3, subsample=(1,1),init=lambda shape, name: normal(shape, scale=0.01, name=name), border_mode='same')\n",
        "    x = Activation('relu')\n",
        "    x = Flatten()\n",
        "    x = Dense(512, init=lambda shape, name: normal(shape, scale=0.01, name=name))\n",
        "    x = Activation('relu')\n",
        "    x = Dense(8,init=lambda shape, name: normal(shape, scale=0.01, name=name))\n",
        "    model = keras.Model(inputs=inputs, outputs=x)\n",
        "    adam = Adam(lr=1e-6)\n",
        "    model.compile(loss='mse',optimizer=adam)\n",
        "    return model\n",
        "\n",
        "\"\"\"\n",
        "# prior to first conv\n",
        "ip = Input(shape=(64, 64, 2))\n",
        "x = CoordinateChannel2D()(ip)\n",
        "x = Conv2D(...)(x)  # This defines the `CoordConv` from the paper.\n",
        "...\n",
        "x = CoordinateChannel2D(use_radius=True)(x)\n",
        "x = Conv2D(...)(x)  # This adds the 3rd channel for the radius.\n",
        "\"\"\"\n",
        "def create_MobileNetV2_model(trainable=False):\n",
        "    model = MobileNetV2(input_shape=(img_channels,img_rows,img_cols), include_top=False)\n",
        "\n",
        "    # to freeze layers\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    x = model.layers[-1].output\n",
        "    x = Conv2D(4, kernel_size=3, name=\"coords\")(x)\n",
        "    x = Reshape((8,))(x)\n",
        "\n",
        "    model = Model(inputs=model.input, outputs=x)\n",
        "    adam = Adam(lr=1e-6)\n",
        "    model.compile(loss='mse', optimizer=adam)\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_train_test_split():\n",
        "    data = np.genfromtxt('Keras-FlappyBird-master/Keras-FlappyBird-master/data.csv', delimiter=',')\n",
        "#    data = np.random.shuffle(data)\n",
        "    traintestsplit = np.split(data, int(data.shape[0]/5))\n",
        "    train = traintestsplit[0]\n",
        "    test = traintestsplit[1]\n",
        "    return train, test\n",
        "\n",
        "# initialize the paths to our training and testing CSV files\n",
        "#TRAIN_CSV = \"flowers17_training.csv\"\n",
        "#TEST_CSV = \"flowers17_testing.csv\"\n",
        "\n",
        "TRAIN, TEST = get_train_test_split()\n",
        "\n",
        "# initialize the number of epochs to train for and batch size\n",
        "NUM_EPOCHS = 75\n",
        "BS = 32\n",
        "\n",
        "# initialize the total number of training and testing image\n",
        "NUM_TRAIN_IMAGES = 0\n",
        "NUM_TEST_IMAGES = 0\n",
        "\n",
        "# open the training CSV file, then initialize the unique set of class\n",
        "# labels in the dataset along with the testing labels\n",
        "#f = open(TRAIN_CSV, \"r\")\n",
        "labels = set()\n",
        "testLabels = []\n",
        "\n",
        "'''\n",
        "# loop over all rows of the CSV file\n",
        "for row in TRAIN:\n",
        "\t# extract the class label, update the labels list, and increment\n",
        "\t# the total number of training images\n",
        "\tlabel = line.strip().split(\",\")[0]\n",
        "\tlabels.add(label)\n",
        "\tNUM_TRAIN_IMAGES += 1\n",
        "\n",
        "# close the training CSV file and open the testing CSV file\n",
        "f.close()\n",
        "f = open(TEST_CSV, \"r\")\n",
        "\n",
        "# loop over the lines in the testing file\n",
        "for row in TEST:\n",
        "\t# extract the class label, update the test labels list, and\n",
        "\t# increment the total number of testing images\n",
        "\tlabel = line.strip().split(\",\")[0]\n",
        "\ttestLabels.append(label)\n",
        "\tNUM_TEST_IMAGES += 1\n",
        "\n",
        "# close the testing CSV file\n",
        "f.close()\n",
        "'''\n",
        "\n",
        "trainLabels = TRAIN[:,1:3]\n",
        "trainData = TRAIN[:,:]\n",
        "np.savetxt('trainData.csv', trainData, delimiter=',')\n",
        "NUM_TRAIN_IMAGES = trainData.shape[0]\n",
        "\n",
        "testLabels = TEST[:,1:3]\n",
        "testData = TEST[:,:]\n",
        "np.savetxt('testData.csv', testData, delimiter=',')\n",
        "NUM_TEST_IMAGES = testData.shape[0]\n",
        "\n",
        "# create the label binarizer for one-hot encoding labels, then encode\n",
        "# the testing labels\n",
        "# lb = LabelBinarizer()\n",
        "# lb.fit(list(trainLabels))\n",
        "# testLabels = lb.transform(testLabels)\n",
        "\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2, fill_mode=\"nearest\")\n",
        "\n",
        "# initialize both the training and testing image generators\n",
        "trainGen = csv_image_generator('trainData.csv', BS, #lb,\n",
        "\tmode=\"train\", aug=aug)\n",
        "testGen = csv_image_generator('testData.csv', BS, #lb,\n",
        "\tmode=\"train\", aug=None)\n",
        "\n",
        "# initialize our Keras model and compile it\n",
        "if usingSimpleCNN:\n",
        "    model = buildSimpleCNN()\n",
        "elif usingSimpleCoordConv:\n",
        "    model = create_COORDCONV_Simple_CNN()    \n",
        "elif usingMobileNetV2Localizer:\n",
        "    model = create_MobileNetV2_model()\n",
        "\n",
        "#    model = MiniVGGNet.build(64, 64, 3, len(lb.classes_))\n",
        "#   opt = SGD(lr=1e-2, momentum=0.9, decay=1e-2 / NUM_EPOCHS)\n",
        "#   model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "# train the network\n",
        "print(\"[INFO] training w/ generator...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=NUM_TRAIN_IMAGES // BS,\n",
        "\tvalidation_data=testGen,\n",
        "\tvalidation_steps=NUM_TEST_IMAGES // BS,\n",
        "\tepochs=NUM_EPOCHS)\n",
        "\n",
        "# re-initialize our testing data generator, this time for evaluating\n",
        "testGen = csv_image_generator(TEST_CSV, BS, #lb,\n",
        "\tmode=\"eval\", aug=None)\n",
        "\n",
        "# make predictions on the testing images, finding the index of the\n",
        "# label with the corresponding largest predicted probability\n",
        "predIdxs = model.predict_generator(testGen,\n",
        "\tsteps=(NUM_TEST_IMAGES // BS) + 1)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(\"[INFO] evaluating network...\")\n",
        "print(classification_report(testLabels.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=lb.classes_))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = NUM_EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"plot.png\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-11130c011140>\"\u001b[0;36m, line \u001b[0;32m71\u001b[0m\n\u001b[0;31m    x = CoordinateChannel2D()(x)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}